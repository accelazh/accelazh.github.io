---
layout: post
title: "Recent Paper Reading RDMA, Learned Index, Dedup"
tagline : "Recent Paper Reading RDMA, Learned Index, Dedup"
description: "Recent Paper Reading RDMA, Learned Index, Dedup"
category: "storage"
tags: [storage, paper, cloud]
---
{% include JB/setup %}


```
1. QuePaxa: Escaping the Tyranny of Timeouts in Consensus    [2023, SOSP23, 1 refs]
   https://expolab.org/ecs265-fall-2023/slices/QuePaxa-DDS.pdf
   https://bford.info/pub/os/quepaxa/quepaxa.pdf
    1. Very good, paradigm shift work from the Paxos algorithm. First invention.
        1. Paxos can be thought as each proposer is broadcasting itself to all replicas. In Paxos, each leader tries to shoot the others (destructive view change). In tcast (QuePaxa), each leader cooperate. The leaders have already determined who should win by random priority attached with proposals. In tcast, they just help broadcast the winner.
        2. QuePaxa can do as good as Multi-Paxos (Leader Paxos) with little more overhead (correctly tune hedge delay). Yet it's more robust to unstable networking delays and timeout configurations. The key is each proposal is attached with a random priority (i.e., ordered), and it changes proposers from shooting each other (destructive view change) to helping winner propagate (cooperative). The protocol is tcast.
    2. Highlights
        1. Concepts
            1. randomized asynchronous consensus core
                1. it's the tcast algorithm
            2. hedging delays
                1. MAB converges to the best leader after a short period of time, who has lower latency
                2. Usecase: a leader is slow, we want to switch to a new faster leader.
                3. difference between hedging and timeout. See paper section 5.1.
            3. multiple proposers to operate simultaneously without destructive interference
                1. tcast tries to broadcast the winner, unlike Paxos each leader broadcasts to shoot the other one.
            4. Adaptively choosing leaders
                1. Simply, just try every leader once. Why saying such a fancy word MAB?
            5. multi-armed bandit theory
                1. It's in the "Adaptively choosing leaders"
            6. tcast - threshold synchronous broadcast
                1. This is the core. QuePaxa is an implementation of tcast.
            7. FLP [27] - asynchronous consensus is deterministically unsolvable
                1. QuePaxa in each round has 1/2 chance to reach consensus. High probability, not saying a must.
                2. Broadcast has an end, that means it needs sync wait barrier here, e.g. in Algorithm 4 "Await R".
            8. fast path under partial synchrony
                1. corresponding to Multi-Paxos by a already-prepared leader
            9. Existence set, common set, universal set
                1. Existent set: Replica i knows Proposal p
                2. Common set: Replica i knows Proposal p is Existent to all replicas
                3. Universal set: Replica i knows Proposal p is Common to all replicas
                4. Proving Theorem (Safety)
                    1. Forget the paper, let's think by ourselves
                        1. From the view of a Replica
                            1. If my best is known by at least N/2+1 other replicas, and my best is the true best, I'm safe to deliver my best
                                1. Is it possible that the true best isn't delivered by the quorum, which incorrect?
                                    1. It implies, the true best is known by at least N/2+1 replicas.
                                       The false best is known by at least N/2+1 replicas.
                                    2. It then implies, the intersection Replica knows the true best, but delivered the false best.
                                       This is impossible.
                            2. So the condition of I can deliver my best is, at least N/2+1 other replicas also knows my chosen best.
                               I.e., I can deliver my best <= my best is in the Common set
                            3. Which can my best be accepted by the quorum, it's at least N/2+1 replicas choose my best.
                               Then, it means at least N/2+1 replicas think my best is in the common set
                               I.e., my best is in the Universal set
                                1. So, a proposal being in the Universal set, implies it will be accepted by the quorum.
                                   Then, this is how comes "if best(ğ¸) = best(ğ‘ˆ ) then deliver(ğ‘£)" in tcast Algorithm 1
                        2. The true question underlying is, we know a Replica should propagate its knowledge, but to what extent the propagation is enough?
                            1. The paper choose to describe in some Common Knowledge theory math.
                5. Proving Theorem (Liveness)
                    1. Since the propagation requires at least N/2+1 Replicas to know something.
                       Then, a replica has >= 1/2 chance to know the true best proposal.
                       After several Rounds, the algorithm is guaranteed to converge, and quite fast
                        1. Even a Round can terminate too early before a Replica finished broadcasting its knowledge
        2. More detailed concepts
            1. When can current round fail to reach consensus
                1. See "Theorem (Liveness)". When the best proposal didn't appear in Replica i's Universal set. Chance is 1/2. Then it has to go to the next round.
            2. What determines the end of each phase (Figure 2)
                1. Each phase maps to one propagate step n Algorithm 1. The end is not associated to timeout, it's logical, i.e. the broadcast done.
                2. Per relaxed, a propagation needs to reach at least N/2+1 Replicas. This is why "Theorem (Liveness)" requires several Rounds to converge to the best answer, and each Round a Replica has 1/2 probability to discover the best proposal.
            3. Leader tuning in QuePaxa
                1. interesting
                2. switch the leader after each epoch, switch to the faster one
                3. monitor leader performance. recompute hedging delay.
        3. How QuePaxa works
            1. 1 Slot = N rounds = N * 4 phases
                1. The first 3 phases, each phase runs an instance of tcast
                2. Algorithm 1
                    1. In phase 1, propagate proposal.
                       In phase 2, propagate existent set.
                       In phase 3, propagate common set.
                       In phase 4, detect consensus by comparing with universal set
                3. 1 Slot maps to a consensus.
                   1 round maps to running full Algorithm 1, may or may not reach consensus.
                   1 phase is a tcast run.
            2. Hedging schedule
                1. Each proposal becomes active after an increasing delay ğ›¿
            3. Auto-tuning automatically converge to the lowest latency leader. Interesting 
                1. MAB, multi-armed bandit.
                2. Try each replica as being leader for 2 epochs. After 2n+1 epochs, it knows the best leader.
                3. Converge to a hedging schedule with replicas sorted in descending order of their observed average epoch completion time.
                4. See Figure 9 leader timeout vs hedging delay. Interesting
                    1. QuePaxa allows setting a low hedging delay between 1/2 to 1x of network roundtrip latency, but Paxos leader timeout cannot do the similar.
            4. Recorder, Interval summary register (ISR)
                1. It's just the logging persistence, and also need to track the max value in each phase with in the active window.
                2. Logical clock = Slot + Round + Phase. it's a measure of the current step.
            5. Fast path: leader-based rounds
                1. like Leader Paxos
        4. Evaluation
            1. Adversarial network
                1. increase egress packet latency of a minority of replicas 
        5. My questions
            1. Geo regional Paxos replication is a right fit. It needs to handle unstable timeouts
                1. metadata plane synchronously replicated across region
            2. How many networking requests are necessary compared to Paxos?
                1. See "How is the overhead of QuePaxa vs Paxos"
            3. Can it still simplify process with a single leader like Leader Paxos?
                1. Yes. Fast Path with leader
            4. Protocol for membership change?
                1. Not mentioned in the paper, worth exploring
            5. Isn't the hedging delay a timeout? Though QuePaxa says not depending on timeout.
                1. Hedging delay needs tuning. But QuePaxa is more robust to a bad Hedge delay configured. See Figure 9.
            6. What if there are >=3 proposers? How can they reach consensus by majority
                1. See protocol details. Paxos has the similar issue, and that's why it may stall liveness.
            7. How is the random priority persistently memorize by the proposer
                1. Not mentioned in the paper. It should be fine for each proposer to persist locally.
            8. How is the overhead of QuePaxa vs Paxos?
                1. If hedge delay is tuned correctly, communication cost is O(n). this is the same with Leader Paxos.
                2. If the leader hits timeout, QuePaxa needs at least 4 phases to reach consensus. Paxos can reach consensus in 2 phases. Each phase is a N to N broadcast.
                3. If networking is unreliable that leader frequently hit timeout, Paxos can stall with liveness issue, because leaders try to shoot each other. But QuePaxa can guarantee to reach consensus in a few slots.
                4. QuePaxa allows switching a slow leader to a faster leader. This is what Leader Paxos can hardly do
            9. What happens if two proposals happen to have chosen the same random priority?
                1. not mentioned in paper
            10. How is fencing done after leader switched?
                1. Not mentioned in paper. Though QuePaxa makes leader switching cheaper, but the fencing does have a cost
            11. Many places in the protocol requiring every replica something. Unlike Paxos which only requires more than half. What will be the implication?
    n. related materials
        1. A game changer for building robust distributed systems - QuePaxa
           https://actu.epfl.ch/news/a-game-changer-for-building-robust-distributed-sys/

2. Farron: Understanding Silent Data Corruptions in a Large Production CPU Population    [2023, 0 refs, SOSP23, Alibaba]
   https://dl.acm.org/doi/pdf/10.1145/3600006.3613149
    1. Good paper. Silent data corruptions from CPU are generally less studied but can easily break common data protection techniques such as replication and EC. Temperature is the key trigger to less reproducible SDCs. Farron invented interesting techniques.
    2. highlights
        1. See Table 1: Most failures were detected in Re-install, i.e. prod running, after preprod testing
            1. Observation 1. In overall, 3.61â€± of the CPUs are identified to cause SDCs in our study
        2. See Table 2: Certain CPU micro-architecture can be ~10x higher failure rate
        3. See Figure 7: Single bit flip is more than ~10x to 2 or more bit flips
        4. Observation 9: Some SDCs are highly reproducible, resulting in large impact on applications.
            1. In 51.2% of the settings, the occurrence frequency is higher than once per minute.
            2. Observation 10: Among those less reproducible SDCs, temperature serves as an important SDC triggering condition
                1. Exponential growth in response to increasing temperature
                2. Minimum triggering temperature exists
                    1. Figure 9, but the occurrence frequency is exponential decreasing whit triggering temperature
                3. Other reasons besides temperature
                    1. instruction usage stress. several orders of magnitude more frequent usage
        5. SDC Mitigation using multiple strategies
            1. include high temperature in SDC testing. But be careful it can affect CPU health
            2. control the CPU temperature at run time, by cooling device, and workload util
        6. Farron: An Efficient SDC Mitigation Tool
            1. temperature controls as a complement to SDC testing
            2. the fine-grained processor decommission (Observation 4)
                1. If more than two cores within a processor are found defective, Farron deprecates the entire processor in line with the pattern presented in Observation 4. Conversely, Farron masks that particular defective core and continues utilizing the other cores as normal.
            3. maintains a reliable resource pool to manage unaffected cores
        7. concrete cases
            1. incorrect checksum calculation
            2. defective hashing calculation in hashmap

3. Perseus: A Fail-Slow Detection Framework for Cloud Storage Systems    [2023, 6 refs, FAST23, Alibaba, Best Paper Award]
   https://www.usenix.org/conference/fast23/presentation/lu
    1. Good. Using latency-vs-throughput (LvT) to detect fail-slow instances, outperformed peer evaluation and all previous attempts. Evaluation on SSDs and HDDs from different clusters.
    2. Highlights
        1. Failure types in datacenter
            1. Fail-slow
                1. Good category. When we evaluate availability, we need to include both Fail-stop and Fail-slow.
                2. Annual fail-slow failure rate is 1-2%
                    1. Contributing most tail latencies
            2. Fail-stop
            3. Byzantine
        2. Fail-Slow Detection (FSD) - Perseus
            1. Challenges
                1. Latency variation may be caused by temporary workload burst, rather than fail-slow issue
                2. Peer evaluation is time-consuming to fine-tune, e.g. the window
            2. Guidelines
                1. Model the latency-vs-throughput (LvT) distribution
                    1. Figure 6, SRCC scores show latency-vs-IOPS is not strongly correlated
                    1. Fit a polynomial regression model
                2. Non-binary output, model likelihood of fail-slow
            3. Designs
                1. Prediction upper bonds as adaptive latency thresholds without fine-tuning
                    1. Interesting. Using outlier detection, and prediction upper bonding.
                2. PCA, DBSCAN, polynomial regression
            4. Findings
                1. In RCA of fail-slow, ill-implemented scheduling (e.g., unnecessary resource contention), occupies 80% root causes.
                    1. Interesting
        3. Evaluation: (Table 5) Threshold vs Peer eval vs IASO vs Perseus 
            1. PERSEUS outperforms all previous attempts
            2. My questions
                1. How exactly does PERSEUS outperforms peer evaluation in details?
                    1. Didn't see paper explaining it
                2. "PERSEUS currently uses traces from 9PM to 12AM each day to reduce interference"
                    1. OK .. this is problematic. The trace can be biased.
                3. "Each node in these two clusters is equipped with 12 open-channel SSDs (OC SSDs), whose Flash Translation Layer (FTL) is managed by the host. For each node, the host allocates 12 CPU cores to manage 12 OC SSDs, respectively (e.g., core0-core11 for SSD0-SSD11)."
                    1. Sounds like Open-channel SSDs are already widely used in Alibaba clusters?
        4. Case study
            1. Ill-Implemented Scheduler
                1. Interesting.
            2. Hardware Defects
                1. Interesting.
    n. related materials
        1. Perseus: A Fail-Slow Detection Framework for Cloud Storage Systems
           https://www.micahlerner.com/2023/04/16/perseus-a-fail-slow-detection-framework-for-cloud-storage-systems.html
        2. Perseus test data released
           https://tianchi.aliyun.com/dataset/144479
            1. good.

4. InftyDedup: Scalable and Cost-Effective Cloud Tiering with Deduplication    [2023, 1 refs, FAST23, 9livesdata]
   https://www.usenix.org/conference/fast23/presentation/kotlarska
    1. First local tier + cloud-based dedup solution for backup system. 
       Commercial product. http://9livesdata.com/publications/ .
       Use cloud to store unique chunks and to carry out batch computation with VM spot instances.
    2. highlights
        1. Scenarios
            1. PBs of backup
            2. public cloud vendors doesn't support dedup
            3. high scalability
            4. dedup is offline.
                1. read from disk then write to disk again
            5. cost of traffic and cost of capacity are unified
                1. cloud selling unifies the prices
                2. so they can compare in GC-Strategy #2.
            6. improve GC by file expiration date
                1. unique user pattern for backup, backup expiration date is known
        2. Cost & Evaluation
            1. Data sets
                1. synthetic workloads in which a given fraction of data was modified and deleted each day
                    1. daily backups are kept for one week, weekly backups are kept for a month, monthly backups are kept for a year, and yearly backups are kept for five years
                    2.  each file is read with a given probability
                2. FSL traces [73]
        3. Mechanism
            1. Data chunking
            2. Leverage cloud infra to Batch Deduplication
                1. we used YARN [76] to schedule jobs, and HDFS [64] for reliable storage of temporary data, so the jobs can be run on spot instances as proposed in the AWS guide [12]
            3. Leverage cloud infra to garbage collect
            4. Moving data chunks to hot/cold tiers
            5. Managing persisted metadata
                1. UFR, PFR
                    1. A container of fingerprint mapped to blocks
                2. Fingerprint index.
            6. Local tier
                1. Minimizing data exchange to cloud
                    1. Local tier uploads UFR (finger print list) to cloud.
                       Cloud identifies unique blocks, send to local tier.
                       Local tier uploads unique blocks to cloud
                2. The local tier can composes of multiple systems
        4. Others
            1. Table 1 cloud storage prices compare. Very useful
        5. My questions
            1. Is pushdown feasible? The cost of fetch data to VM and then write down is much higher
            2. Can the background processing be co-scheduled with cloud workload to pick a more idle time?

    n. related materials
        1. Hydrastor: A scalable secondary storage    [2009, 367 refs, FAST09, 9livesdata]
           https://www.usenix.org/conference/fast09/technical-sessions/presentation/dubnicki
            1. Referenced in the main paper as "We integrate InftyDedup with HydraStor [33], a commercial backup system with deduplication"
            2. Highlights
                1. A file is organized as a tree of blocks (DAG). Only leaves are data.
                2. DHT data placement
                3. Data stream split to blocks
                4. Inline deduplication

5. Characterizing, Modeling, and Benchmarking RocksDB Key-Value Workloads at Facebook    [2020, 256 refs, Facebook]
   https://www.usenix.org/conference/fast20/presentation/cao-zhichao
    1. Analyzed workload characterization in details in RocksDB at Facebook
    2. Highlights
        1. Application traces
            1. UDB, ZippyDB, UP2X
            2. UDB
                1. Social graph data maintained in MySQL tables. Table rows stored as KV-pairs in RocksDB. I.e. MyRocks engine
            3. ZippyDB
                1. Distributed KV-store that uses RocksDB as backend. Usually stores photo metadata and object metadata
            4. UP2X
                1. UP2X is a special distributed KV-store based on RocksDB.
                2. UP2X stores the profile data (e.g., counters and statistics) used for the prediction and inferencing of several AI/ML services at Facebook.
                3. Therefore, the KV-pairs in UP2X are frequently updated
                4. Compaction Filter: delete keys during compaction without Delete operation
        2. Dimensions of workload characterization
            1. Query Composition: Get, Put, Delete, Single Delete, read-modify-write (Merge), Iterator
            2. Key size distribution
            3. Value size distribution
            4. Query Per Second (QPS) daily pattern
            5. KV-pair Hotness and Access Count Distributions
            6. Access Heat-map vs Key space
            7. Key-Space and Temporal Localities
        3. New benchmark vs YCSB
            1. Key-range hotness
                1. we use average number of KV-pairs per SST file as key-range size
                2. a Generalized Pareto Distribution [25]
                    1. ä»€ä¹ˆæ˜¯å¸•ç´¯æ‰˜åˆ†å¸ƒï¼Ÿ
                       https://www.zhihu.com/question/25498346
                        1. å¸•ç´¯æ‰˜åˆ†å¸ƒæ˜¯ä¸€ä¸ªskewedï¼Œåšå°¾(fat-tailed)åˆ†å¸ƒ
                    2. Wikipedia: Generalized Pareto distribution
                       https://en.wikipedia.org/wiki/Generalized_Pareto_distribution
                        1. GPD is often used to model the tails of another distribution.
            2. Load a snapshot of the database and then replay reads
        4. My questions
            1. Garbage collection pattern is not analyzed?

    n. related materials
        1. MyRocks: LSM-Tree Database Storage Engine Serving Facebook's Social Graph    [2020, 75 refs, VLDB, Facebook]
           https://www.vldb.org/pvldb/vol13/p3217-matsunobu.pdf
            1. UDB
            2. How is query supported in RocksDB to match B+tree index?
                1. Point lookup
                    1. Memory table
                       Global index => levels => SSTs. Locating SSTs should be able to done in memory.
                       SST has an index block for binary search. Need disk reads.
                2. Range query
                    1. Prefix bloom filter to skip levels (sorted runs)
                    2. SingleDelete to walkaround tombstone overhead
                3. How is secondary index supported?
                    1. covering_index technique, by include all relevant columns in the index, so range scan can be completed without randomly reading from primary keys
                       https://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos
                    2. Didn't see details. I guess secondary index is just another table. But how to maintain consistency?
            3. How is space made efficient given GC and levels?
                1. The MyRocks instance size was 37.7% compared to the InnoDB instance size with the same data sets
                    1. For InnoDB, space amplification mostly comes from fragmentation and less efficient compression.
                        1. InnoDB wasted 25-30% space in fragmentation
                        2. Also, InnoDB has significant space overhead per row for handling transactions
                    2. LSM-tree's dead data is removed by compaction, and by tuning compaction, we are able to maintain the ratio of dead data to as low as 10% [14]
                        1. Optimizing space amplification in RocksDB    [2017, 216 refs, CIDR]
                           https://www.cidrdb.org/cidr2017/papers/p82-dong-cidr17.pdf
                        2. If 16KB data was compressed to 5KB, RocksDB uses just 5KB while InnoDB aligns to 8KB, so RocksDB is much more space efficient

        2. Optimizing space amplification in RocksDB    [2017, 216 refs, CIDR, Facebook]
           https://www.cidrdb.org/cidr2017/papers/p82-dong-cidr17.pdf
            1. How to "we are able to maintain the ratio of dead data to as low as 10%"?
                1. RocksDB uses two strategies to reduce space amplification:
                    1. adapting the level sizes to the size of the data, and
                        1. The next level is 10x the size of the previous level
                            1. "For most of the Facebook production RocksDB installations, a size multiplier of 10 is used, although there are a few instances that use 8."
                    2. applying a number of compression strategies
                        1. Key prefix encoding
                        2. Sequence ID removed after GC
                        3. Dictionary-Based Compression

6. CFS: Scaling Metadata Service for Distributed File System via Pruned Scope of Critical Sections    [2023, 2 refs, EuroSys23]
   https://dl.acm.org/doi/10.1145/3552326.3587443
   https://mp.weixin.qq.com/s/1uQ1yRq0letKDVTaFDtXTA
    1. POSIXå…¼å®¹ã€å¼ºä¸€è‡´ã€æ¨ªå‘æ‰©å±•ï¼Œä½¿ç”¨æ•°æ®åº“TafDBç®¡ç†å…ƒæ•°æ®, RocksDB to mange file contents. Key designs
        1) Co-locating metadata, so most operations touch only one shard.
        2) Offloading file attributes to FileStore. They are not stored in metadata service.
        3) Use atomic primitives rather than locking to update ctime, mtime, atime.
        4) Rename/Move is serialized by Renamer, which is backed by Raft
    2. Highlights
        1. Key architecture
            1. é˜¶æ®µä¸‰ï¼šåˆ†ç¦»å¼å…ƒæ•°æ®æ¶æ„
                1. æ•°æ®åº“å±‚ï¼šè¿™ä¸€å±‚è´Ÿè´£æ•°æ®å­˜å‚¨ï¼Œé€šå¸¸é‡‡ç”¨ NewSQL æˆ–åˆ†å¸ƒå¼ KV ç³»ç»Ÿï¼ˆä»¥ä¸‹ç»Ÿç§° Table ç³»ç»Ÿï¼‰ï¼Œå®ç°æ•°æ®çš„æŒä¹…åŒ–çš„åŒæ—¶æä¾›åˆ†å¸ƒå¼äº‹åŠ¡èƒ½åŠ›
                   å…ƒæ•°æ®ä»£ç†å±‚ï¼šè¿™ä¸€å±‚å¯¹å¤–æä¾› POSIX æˆ– HDFS æ¥å£ï¼Œå¯¹å†…å°†å±‚çº§å‘½åç©ºé—´çš„æ•°æ®è½¬æ¢æˆ Table ç³»ç»Ÿä¸­çš„è®°å½•ï¼Œå¤„ç†æ—¶åˆ©ç”¨äº‹åŠ¡ä¿è¯æ“ä½œçš„æ­£ç¡®æ€§
                2. æ–‡ä»¶å±æ€§åˆ†ç¦»
                    1. æ–‡ä»¶å±æ€§ï¼ˆfile attributesï¼‰ä»å…ƒæ•°æ®æœåŠ¡ä¸­å‰¥ç¦»å‡ºæ¥ï¼Œå’Œæ–‡ä»¶æ•°æ®ï¼ˆfile dataï¼‰ä¸€èµ·æ”¾åˆ°æ•°æ®æœåŠ¡ï¼ˆData Serviceï¼‰ä¸­è¿›è¡Œå¤„ç†
                        1. My questions
                            1. How to ensure atomic update on the file content and file attributes?
                            2. How does co-locating work for file attributes if they are pushed down to FileStore?
                    2. Namespace 2.0: Instead of locking the entire file, use atomic variables to update ctime, mtime, atime.
                        1. Single-shard atomic primitives
                3. è¯»å†™åˆ†ç¦»
                    1. å¯¹äºè¯»è¯·æ±‚ï¼Œæˆ‘ä»¬ç»•è¿‡äº†å…ƒæ•°æ®ä»£ç†å±‚ç›´æ¥è®¿é—® TafDB
                    2. Serializable Snapshot Isolation
                        1. æˆ‘ä»¬å†³å®šå°†æ¯ä¸ªæ–‡ä»¶ç³»ç»Ÿçš„å†™è¯·æ±‚æ”¶ç¼©åˆ°ä¸€ä¸ªå•ç‚¹è¿›è¡Œå¤„ç†ï¼Œå†™æ‰©å±•æ€§å’Œå†™å»¶æ—¶çš„é—®é¢˜ç•™åˆ°ä»¥åå†å»è§£å†³ã€‚
            2. TafDB
                1. Distributed table DB with partition split
            3. Renamer
                1. handling complex rename operations that are metadata-intensive
                2. Serialize all transaction into one node. E.g. rename, move.
                3. Multi-Raft æ¶æ„ï¼Œæ¯ä¸ªæ–‡ä»¶ç³»ç»Ÿç”±ä¸€ä¸ª Raft å¤åˆ¶ç»„æä¾›å¯¹å¤æ‚ renameï¼Œå³æ‰€è°“ Normal Path rename çš„æ”¯æŒ
            4. ClientLib
                1. ClientLib collapses the metadata proxy layer into the client side
                2. Move metadata prox into ClientLib. Metadata proxy is not needed any more.
                3. ç›®å‰æ”¯æŒ FUSEã€Sambaã€NFS-Ganesha
            5. åˆ†å¸ƒå¼é”
                1. ä¸Šè¿°çš„å®éªŒè¡¨æ˜ï¼Œé”å†²çªæ˜¯å½±å“ç³»ç»Ÿæ‰©å±•æ€§å’Œæ“ä½œå»¶æ—¶çš„å…³é”®ã€‚
                    1. å½“å†²çªæ¯”ä¾‹ä¸º 50% å’Œ 100% çš„æ—¶å€™ï¼Œé”å†²çªåœ¨æ•´ä¸ªæ“ä½œä¸­çš„å æ¯”é«˜è¾¾ 83.18% å’Œ 93.86%
                    2. å³ä½¿åœ¨æ— å†²çªçš„æƒ…å†µä¸‹ï¼Œé”åœ¨æ•´ä¸ªæ“ä½œé‡Œçš„è€—æ—¶å æ¯”ä¹Ÿè¾¾åˆ°äº† 52.9%
            5. FileStore
                1. Backed by RocksDB, to store file contents, and file attributes
            6. Caching
                1. ç”±äºæ¯ä¸ªæ–‡ä»¶ç³»ç»Ÿçš„å…ƒæ•°æ®å†™éƒ½æ˜¯å•ç‚¹ï¼ŒNamespace æ¨¡å—ä»»ä½•æ—¶åˆ»çœ‹åˆ°çš„æ•°æ®éƒ½æ˜¯æœ€æ–°çš„ï¼Œå…·å¤‡å¼•å…¥ç¼“å­˜çš„æ¡ä»¶ï¼Œç¼“å­˜å‘½ä¸­æƒ…å†µä¸‹äº‹åŠ¡ä¸­çš„å¤§éƒ¨åˆ†è¯»è¯·æ±‚éƒ½å¯ä»¥è¢«ä¼˜åŒ–æ‰
        2. Key challenges
            1. å…³è”å˜æ›´ã€åŸå­æ€§
                1. ä¾‹å¦‚åˆ›å»ºå­æ–‡ä»¶ã€æ›´æ–°çˆ¶å±æ€§ctime
                2. How does CFS reduce locking overhead in metadata operations?
                    1. co-locating related metadata into one node. only single-shard atomic primitives are needed
            2. rename
            3. è·¯å¾„æŸ¥æ‰¾
                1. <çˆ¶ç›®å½• inode, å­é¡¹åç§°> ç´¢å¼•
                2. <inode> ç´¢å¼•
            4. è·å–å±æ€§
            5. èŒƒå›´è¯»ï¼Œç›®å½•éå†
    n. related materials
        1. å¦‚ä½•å°†åƒäº¿æ–‡ä»¶æ”¾è¿›ä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿï¼ŒEuroSys'23 CFS è®ºæ–‡èƒŒåçš„æ•…äº‹
           https://mp.weixin.qq.com/s/1uQ1yRq0letKDVTaFDtXTA
            1. ç™¾åº¦æ²§æµ·Â·å­˜å‚¨å›¢é˜Ÿ - ç™¾åº¦æ™ºèƒ½äº‘æ–‡ä»¶å­˜å‚¨ CFS çš„å…ƒæ•°æ®ç³»ç»Ÿ
            2. good, well-explained DFS challenges
        2. HopsFS
        3. InifiniFS

7. OceanBase: LCL: A Lock Chain Length-based Distributed Algorithm for Deadlock Detection and Resolution    [2023, 0 refs, Alibaba, ICDE23]
    1. OceanBase æå‡ºçš„æ–¹æ³• LCL æ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„ç«äº‰å¯¹æ‰‹ M&M ç®—æ³•. Compared to CockroachDB's, LCL only needs to pass numbers across the graph. 
    2. highlights
        1. å¦‚è¡¨1 æ‰€ç¤ºï¼Œå½“å‰çš„æ­»é”æ£€æµ‹ä¸æ¶ˆé™¤ç®—æ³•ä¸»è¦æœ‰å››ç§
            1. é›†ä¸­å¼æ­»é”æ£€æµ‹ï¼ŒåŸºæœ¬æ€æƒ³æ˜¯é€‰æ‹©ä¸€ä¸ªä¸­å¿ƒèŠ‚ç‚¹ä½œä¸ºæ£€æµ‹å™¨ï¼Œæ”¶é›†æ‰€æœ‰èŠ‚ç‚¹çš„é”ç­‰å¾…å…³ç³»ï¼Œç”Ÿæˆå…¨å±€é”ç­‰å¾…å›¾ï¼ˆWFGï¼‰ï¼Œåº”ç”¨æ¡ˆä¾‹ä¸ºTiDB[1]ã€‚è¿™ç§æ–¹æ³•çš„ç¼ºç‚¹æ˜¯å…¸å‹åº”ç”¨çš„é”ç­‰å¾…å…³ç³»é€šå¸¸è¾ƒä¸ºç®€å•ï¼Œæ•´åˆæ‰€æœ‰å±€éƒ¨ WFGï¼ˆwait for graphï¼‰çš„å¼€é”€è¾ƒå¤§ï¼›
            2. æ­»é”é¢„é˜²ç­–ç•¥ï¼ŒåŸºæœ¬æ€æƒ³æ˜¯åœ¨æ­»é”å‘ç”Ÿä¹‹å‰é€šè¿‡ Wound-Waitï¼ŒWait-Die ç­‰ç­–ç•¥æœ‰é€‰æ‹©åœ°æ€æ­»äº‹åŠ¡ï¼Œåº”ç”¨æ¡ˆä¾‹ä¸ºGoogle Spanner[2]ã€‚è¿™ç§æ–¹æ³•çš„ç¼ºç‚¹æ˜¯å¤§é‡ä¸ä¼šå¯¼è‡´æ­»é”çš„äº‹åŠ¡è¢«æ€æ‰ï¼Œç”¨æˆ·æ— æ³•æ¥å—ï¼›
            3. è·¯å¾„æ¨åŠ¨ç®—æ³•(Path pushing)ï¼ŒåŸºæœ¬æ€æƒ³æ˜¯åœ¨æ¯ä¸ªé¡¶ç‚¹æ„å»ºå±€éƒ¨WFGï¼Œæ¯ä¸ªé¡¶ç‚¹å°†å…¶æœ¬åœ°WFGå‘é€åˆ°å¤šä¸ªç›¸é‚»èŠ‚ç‚¹ï¼Œå¹¶é‡å¤æ­¤è¿‡ç¨‹ã€‚ç›´åˆ°æŸä¸ªé¡¶ç‚¹æœ‰è¶³å¤Ÿçš„è§†å›¾æ¥å®£å¸ƒæ­»é”ï¼Œåº”ç”¨æ¡ˆä¾‹ä¸º CockroachDB[3]ã€‚è¿™ç§æ–¹æ³•çš„ç¼ºç‚¹æ˜¯å¤šä¸ªé¡¶ç‚¹ä¼šæ£€æµ‹åˆ°åŒä¸€ä¸ªæ­»é”ï¼Œæ¯ä¸ªé¡¶ç‚¹éƒ½è¯•å›¾é€šè¿‡æ€æ­»ä¸€äº›äº‹åŠ¡æ¥æ¶ˆé™¤æ­»é”ï¼Œè¿™å¯èƒ½å…·æœ‰å¤šæ€æ€§ï¼›
            4. è¾¹è¿½é€ç®—æ³•(Edge chasing)ï¼ŒåŸºæœ¬æ€æƒ³å°±æ˜¯æ²¿ç€äº‹åŠ¡ WFG çš„è¾¹ä¼ æ’­å…·æœ‰ç‰¹æ®Šæ„ä¹‰çš„æ¶ˆæ¯ï¼Œæ­»é”äº§ç”Ÿçš„ç¯è·¯å…³ç³»æœ€ç»ˆå°†å¯¼è‡´æ¶ˆæ¯è¿”å›åˆ°å®ƒçš„å‘èµ·è€…å¤„ï¼Œä»è€Œæç¤ºæ­»é”çš„å­˜åœ¨ï¼Œåº”ç”¨æ¡ˆä¾‹ä¸º Oracle RACå’Œ OceanBase[4]ã€‚
        2. Algorithm
            1. ç¹æ®–é˜¶æ®µã€æ‰©æ•£é˜¶æ®µå’Œæ£€æµ‹é˜¶æ®µ
            2. ASG(scc) ä¸­ä»»ä½• LCLV æœ€å¤šåœ¨ AsgWidth(scc) è½®æ¨æ¼”ä¹‹åä¼ æ’­åˆ° scc
            3. å¦‚æœä¸é™åˆ¶ç¹æ®–è¿‡ç¨‹çš„æ—¶é—´ï¼Œå¾ªç¯ä¸Šé¡¶ç‚¹çš„ LCLV å¯ä»¥æ— é™å¢å¤§ï¼Œæ‰€ä»¥ LCL ç®—æ³•é‡Œé¢ä¼šè®¾ç½®æ—¶é—´ä¸Šé™
            4. ç¹æ®–é˜¶æ®µçš„æ—¶é—´å¤æ‚åº¦ä¸º O(N)ï¼Œå…¶ä¸­ N æ˜¯ WFG ä¸­æœ‰å‘è¾¹çš„æ•°é‡
            5. WFGä¸­åªè¦å­˜åœ¨æ­»é”å°±ä¼šæœ‰ sccï¼Œåªè¦å­˜åœ¨ scc å°±è‚¯å®šæœ‰ä¸€ä¸ªæœ€é¡¶å±‚ sccï¼Œè¯¦ç»†è¯æ˜è¿‡ç¨‹è§è®ºæ–‡é™„å½•
            6. cycle leads to infinite lock chain length (LCLV) growth.
            7. Figure 9 shows SCC, USC, and how the algorithm works
                1. My questions
                    1. Per deadlock resolution, which victim transactions should be aborted?
                        1. Probably those in SCC
        3. vs M&M
            1. M&M å’Œ LCL ä¸»è¦å·®å¼‚åœ¨äº: M&M å‡è®¾äº‹åŠ¡ç­‰å¾…å•ä¸€èµ„æºï¼ŒLCL å¯¹äº‹åŠ¡å¯ä»¥ç­‰å¾…çš„èµ„æºæ•°é‡æ²¡æœ‰ä»»ä½•é™åˆ¶
        4. Others
            1. äº‹åŠ¡æ‰§è¡Œæ¨¡æ‹Ÿå™¨ï¼ˆTPEï¼‰
    n. related materials
        1. å›½é™…é¡¶ä¼š ICDEå…¥é€‰ | OceanBase æ­»é”æ£€æµ‹å®ç°äº†å“ªäº›æŠ€æœ¯çªç ´ï¼Ÿ
           https://zhuanlan.zhihu.com/p/624847601?utm_id=0
        2. CockroachDBæ­»é”å¤„ç†
           https://zhuanlan.zhihu.com/p/449151313
           https://zhuanlan.zhihu.com/p/472573422

8. MemBalancer: Optimal Heap Limits for Reducing Browser Memory Use    [2022, 1 refs, OOPSLA22]
   https://arxiv.org/abs/2204.10455
   https://www.bilibili.com/video/BV1Yj411977B/
    1. The square-root rule has wide applicable value for resource over-provisioning, e.g. caching, memory, reservation, bursts.
       But note, Square-root rule is derived in the context of garbage collection, and garbage grows at a constant speed g.
       Built upon Javascript engine V8. Evaluation shows MemBalancer can reduce GC time by almost 50% given the same memory usage.
       Good, but,
        1. My questions
            1. Why not just watch the speed of each heap grows and customize heap size?
            2. Why GC time is calculated by L/s, rather than M/s or (M-L)/s
    2. highlights
        1. key algorithms
            1. setting a small heap limit has trade off of longer and more frequent GC time
            2. Instead of individual limit for each heap, use a shared limit for all heaps
            3. derive the optimal heap limit by the "square-root" rule. it achieves coordination without communication
        2. The author's explanation
            1. "ä¸€èˆ¬æ¥è¯´ï¼Œä¸€ä¸ªruntimeä¼šæœ‰ä¸€ä¸ªheap limitï¼ˆLï¼‰ï¼Œå½“ç¨‹åºæ¶ˆè€—å†…å­˜é‡è¾¾åˆ°limitåï¼Œåˆ™ä¼šè¿›è¡Œåƒåœ¾å›æ”¶ï¼Œä½¿å¾—å†…å­˜ä½¿ç”¨é‡ä¸‹é™åˆ°limitä»¥ä¸‹ã€‚å‡è®¾ç¨‹åºè‡ªå·±çš„live set sizeï¼ˆæ— æ³•è¢«GCæ¸…æ‰çš„ï¼Œè¿˜åœ¨ç”¨ç€çš„å†…å­˜ï¼‰æ˜¯S, é‚£ä¸€èˆ¬æ¥è¯´ï¼Œä¼šè®¾ç½®æˆL = N * Sï¼Œå…¶ä¸­Næ˜¯ä¸€ä¸ª2ä¹‹ç±»çš„å¸¸æ•°ã€‚è¿™ä»£è¡¨ç€ï¼Œä¸€ä¸ªå¸¦GCçš„ç¨‹åºçš„æœ€å¤§å†…å­˜ä½¿ç”¨é‡ï¼Œåº”è¯¥æ˜¯æ‰‹åŠ¨å†…å­˜ç®¡ç†çš„å†…å­˜ä½¿ç”¨é‡çš„ä¸¤å€ã€‚

                ä½†ï¼Œè¿™å…¶å®å¹¶ä¸åˆç†ï¼æˆ‘ä»¬åœ¨paperé‡Œé¢å¯¹åƒåœ¾å›æ”¶è¿›è¡Œæ•°å­¦å»ºæ¨¡ï¼Œç„¶åå¯»æ‰¾ä¸€ä¸ªè¿™ä¸ªé—®é¢˜çš„æœ€ä¼˜è§£ã€‚æˆ‘ä»¬æœ€åå‘ç°ï¼Œåº”è¯¥è®¾ç½®æˆL = S + N * Sqrt(S)ï¼Œå°±æ˜¯è¯´ - Sè¶Šå¤§ï¼Œæˆ‘ä»¬å¯¹åº”äºåŸå…ˆçš„ç®—æ³•ï¼Œåº”è¯¥ç»™çš„å†…å­˜è¶Šå°ï¼è¿™æ—¶å€™ï¼Œæˆ‘ä»¬çš„ç®—æ³•åœ¨v8 javascript engineä¸Šå¯ä»¥æ¯”åŸå…ˆçš„GCå¿«30%ï¼ˆåŒç­‰å†…å­˜ï¼‰ï¼Œåˆæˆ–è€…åŒç­‰æ—¶é—´ä¸‹èŠ‚çœ15%çš„å†…å­˜ã€‚æˆ‘ä»¬çš„ç®—æ³•ä¹Ÿå®ç°è¿›äº†racketï¼Œä¹Ÿä¸€æ ·æœ‰å¾ˆå¥½çš„ç»“æœã€‚

                è¿™å¯¹åº”ç€ç»æµå­¦çš„è¾¹é™…æ•ˆç”¨é€’å‡åŸç† - å¯¹äºä¸€ä¸ªç”¨äº†å¾ˆå¤šå†…å­˜çš„VMï¼Œæˆ‘ä»¬å†å¤šç»™ä¸€äº›å†…å­˜ï¼Œå¹¶ä¸ä¼šé€ æˆå¾ˆå¤§å½±å“ã€‚ä½†æ˜¯å¯¹äºä¸€ä¸ªåªç”¨äº†ä¸€ç‚¹ç‚¹å†…å­˜çš„VMï¼Œå†å¤šç»™åŒæ ·å¤šçš„å†…å­˜ï¼Œä¼šé€ æˆæ›´æ˜¾è‘—çš„å½±å“ã€‚åšä¸€ä¸ªå¥‡æ€ªçš„ä¾‹å­ï¼Œä½ væˆ‘50åƒè‚¯å¾·åŸºç–¯ç‹‚æ˜ŸæœŸå››ï¼Œè·Ÿä½ v Bill Gate 50ï¼Œæ˜¯å®Œå…¨ä¸ä¸€æ ·çš„æ¦‚å¿µ - äººå®¶ä¸å·®ä½ è¿™50ï¼Œä½†æˆ‘å·®ã€‚KFCï¼Œå¾ˆå¥‡å¦™å§ã€‚"
            2. Square-root rule
                1. GC overhead = GC frequency * GC time = g/(M-L) * L/s
                   Summing up each heap's overhead
                2. Optimize: minimize sum of overhead
                             keep constant sum of M 
                   They we get we need M = L + c*sqrt(L)
                3. "For sum ratio to be minimized, a kind of â€œno-arbitrage conditionâ€ needs to hold: reducing one tab's heap limit by a tiny amount and then increasing another tab's heap limit by the same amount should not impact sum ratio. Therefore, ğœ•ratio/ğœ•ğ‘€ must be equal for all tabs."
            3. My questions
                1. Why not just watch the speed of each heap grows and customize heap size?
                2. Why GC time is calculated by L/s, rather than M/s or (M-L)/s
    n. related materials
        1. OOPSLA 2022æœ‰ä»€ä¹ˆå€¼å¾—å…³æ³¨çš„è®ºæ–‡ï¼Ÿ
           https://www.zhihu.com/question/559160156/answer/2722391734
            1. The author's in personal reply
        2. TMO: Transparent Memory Offloading in Datacenters

9. Orthus/NHC: The Storage Hierarchy is Not a Hierarchy: Optimizing Caching on Modern Storage Devices with Orthus    [2021, 32 refs, FAST21]
   https://www.usenix.org/conference/fast21/presentation/wu-kan
    1. Allow overloaded cache hits to be offloaded to the lower layer slower device.
       The key takeaways, we should combine the max throughput of both cache + capacity device.
       Evaluation shows overall throughput improvement by ~20%.
    2. Highlights
        1. Non-Hierarchical Caching (NHC)
            1. Problems to solve
                1. The differences between today's neighboring layers are less clear and even overlapping (depending on workloads)
                2. Due to introducing Intel Optane SSD
            2. Non-Hierarchical Caching (NHC)
                1. Key idea: augmenting caching with dynamic load admission and request offloading
                2. avoid excess load to cache device when it is saturated, e.g., too many cache hits
                    1. Classic caching is (data_admit = true, load_admit_ratio = 100%)
                    2. Tune load_admit_ratio
                        1. Turn off data admission for read misses
                        2. feedback-based tune small step by step

10. Empowering Azure Storage with RDMA    [2023, 15 refs, microsoft, NSDI23]
    https://www.usenix.org/conference/nsdi23/presentation/bai
    1. Good. Azure Storage's experience of onboarding RDMA and DCQCN. Probably the largest RDMA deployment in the world
    2. Highlights - talk
        1. Why important?
            1. Majority of network traffic is storage-related
                1. ~70% percent of total
            2. Optimizing brings cost saving and better performance
                1. Sell freed-up CPU cores in compute
                2. Buy cheaper servers in storage
                3. Lower IO latency and jitter
        2. RDMA
            1. Offload network traffic from general purpose CPU
                1. NIC handles all DMA
            2. Performance
                1. RDMA single thread ~40Gbps
                2. RDMA latency 1~2 us
                3. Current NIC can achieve ~100Gbps for a single flow
            3. Our choice - RoCEv2
                1. Compatible with Ethernet/IP. Hence cheap
                2. Can scale to DC and beyond
                3. InfiniBand (IB) is completely custom stack (L1-L7)
        3. Challenges
            1. RoCEv2: PFC, buffer management, congestion control, etc
                1. PFC
                    1. Put InfiniBand L4 it into UDP packet
                    2. "InfiniBand L4" doesn't like packet drop - Lossless Ethernet
                        1. RoCEv2 relies on Priority-based Flow Control (PFC) to make the network lossless.
                        2. But, PFC has problems at scale. It sends PAUSE frames to pause upstream sender when queue > threshold. HOL blocking
                            1. But ... PFC is problematic at scale. Sending a spike of PAUSE frames
                                1. E.g., the switch sends PFC pause frames from port 1 and 2, but Flow 3 is paused though it doesn't create any congestion 
                                2. Solution: PFC as last resort - DCQCN
                                    1. Still use PFC, it's needed for IB transport
                                    2. But minimize PFC generation. Per-flow E2E Congestion Control
                                    3. This is DCQCN
                                        1. ECN-based, RTT-oblivious congestion control
            2. Tailor storage code for RDMA
                1. sU-RDMA additions for storage backend
                    0. sU-RDMA: storage user space RDMA
                    1. Translate sockets API to RDMA verbs
                    2. Multiple transfer modes based on message sizes
                    3. Automatic TCP/RDMA failover
                        1. RDMA doesn't like congestion rates. When you have a bad link that corrupting packets, TCP would be OK, but RDMA doesn't. You would have automated system to remove that link, but there still would be a few minutes that it suffers. In this window, you need RDMA to fall back to TCP.
                    4. Still passing through the OS kernel
                        1. My questions
                            1. Why not DPDK?
            3. Performance monitoring: RDMA Estats
                1. On host: RDMA Estats and NIC counters
                    1. Akin to TCP Estats.
                        1. It provides fine-grained latency breakdown for each RDMA operation between CPU/NIC/Remote NIC
                        2. Be careful to sync the CPU clock and NIC clock
                2. On routers: standard router telemetry
                    1. PFCs sent and received, per-queue traffic and drop counters, special PFC WD summary
            4. And many others
                1. Lessons learned
                    1. Focus more on "system" consideration
                        1. than details of congestion control algorithms
                    2. Design must accommodate legacy hardware and heterogeneity
                        1. No greenfield designs
                        2. Test, test, test
                    3. Monitoring, serviceability and backward compatibility are primary considerations
                        1. Cannot be bolted on later
                    4. Some tuning is unavoidable
                        1. Implementation details matter
                        2. Traffic patterns evolves
                        3. Router buffer management is complicated.
                    5. Joint design
                        1. Layering is good, but have gaps
                        2. Host networking stack, routing, buffer management must work together to deliver high performance
    3. Highlights - paper
        1. Combines RDMA send/write for different message sizes: [87] Transport protocol and interface for efficient data transfer over rdma fabric
        2. sK-RDMA fully kernel model RDMA, rather than fully user mode
        3. RDMA Extended Statistics like TCP's
        4. SONiC switch OS
        5. Hardware programmable traffic generator [9]
        6. Long links over T2 and RH
            1. deep packet buffers of off-chip DRAM
            2. shared PFC headroom pool and being oversubscribed with a reasonable ratio
        9. Figure 10, why SSD read/write latency with TCP vs RDMA are not much different? 
        10. Figure 11, DCQCN withOUT a right config can mess up the latency
        11. Message chunking, only allowing a single in-flight chunk, effective to mitigate high-degree incast 
        12. Switch/NIC firmware at scale can have bugs in performance plane
        13. Open problems for future
            1. Failovers are very expensive for RDMA. Think the extra CPU needs to be provisioned for falling over to TCP
            2. Host network and physical network should be converged. Speed of networking is catching up with intra host
            3. Switch buffer has a strong correlation with RDMA performance problems, need more buffer as higher link speed and farther distance
    
    n. related materials
        1. DCQCN: Congestion Control for Large-Scale RDMA Deployments
           https://conferences.sigcomm.org/sigcomm/2015/pdf/papers/p523.pdf
        2. è®ºæ–‡ç¬”è®°ï¼šå¾®è½¯ Azure ç½‘ç»œæ¼”è¿› - Pavinberg
           https://zhuanlan.zhihu.com/p/624228199
            1. Many papers listed, useful 

        3. Metaï¼šå¤§è§„æ¨¡åˆ†å¸ƒå¼AIè®­ç»ƒçš„RoCEç½‘ç»œï¼ˆè®ºæ–‡ï¼‰ - Andy730
           https://mp.weixin.qq.com/s/7oLhn51h1NE-XIZn_UOm3g

11. Distributed Transactions at Scale in Amazon DynamoDB    [2023, 0 refs, ATC23]
   https://www.usenix.org/conference/atc23/presentation/idziorek
    1. 2PC snapshot read and atomic write transaction implemented on KV store without MVCC. Serializable level.
       Timestamp ordering is implemented with OCC. Non-transaction RW pays no cost.
       Interesting optimizations on transaction read/write leveraging no MVCC support.
    2. Highlights
        1. Key design points
            1. Transaction is implemented by 2PC
            2. Non-transaction operations don't pay for transaction
            4. Transaction update items in place, no MVCC
                1. The implication of a single-version store for transaction processing is that read-only and read-write transactions might conflict
            5. Transactions are serially ordered using timestamps
                1. The clocks in the coordinator fleet are sourced from the AWS time-sync service [1]
                    https://aws.amazon.com/blogs/aws/keeping-time-with-amazon-time-sync-service/
                    1. NTP based
                    2. Aurora Limitless made TimeSync similar with Google TrueTime
                       https://zhuanlan.zhihu.com/p/670412648
                       https://youtu.be/a9FfjuVJ9d8?si=oEH5WM-zvpCD9dP8&t=1942
                1. Transactions do not acquire locks, use OCC
            7. Transaction semantics
                1. TransactGetItems - get a consistent snapshot
                2. TransactWriteItems - atomic write set
                3. CheckItem - check condition and write
        2. transaction coordinator
            1. Write Tx
                1. The storage node accepts the transaction if
                    1. The transaction's timestamp is greater than the item's timestamp indicating when it was last written
                        1. My questions
                            1. See Listing 3 "AND item . ongoingTransactions == NONE". This means a prepared item would reject any other Tx prepares. Isn't it a locking?
                    2. each participant storage node performs the desired writes on its local items and records the timestamp of the transaction as the items' last write timestamp.
                2. Items for which a precondition was checked but that are not being written also have their timestamps updated.
                    1. Interesting
            2. Read Tx
                1. OCC - read twice with data and LSN. If LSN no change in middle, read can succ
                    1. My questions
                        1. What about atomicity? It seems nothing prevents reading a half committed write Tx
            3. Recovery and fault tolerance
                1. coordinators maintain a persistent record of each transaction and its outcome in a ledger
                2. multiple Transaction coordinators. OK to reassign a slow transaction
                3. it is okay for multiple coordinators to be finishing the same transaction at the same time since duplicate attempts to write an item are ignored by its storage node
                    1. interesting
        3. optimizations
            1. Inserting transaction timestamp
                1. Read/write to individual item can succ even the item has prepared for a transaction.
                   The timestamp is generated as in middle of (the last time, the prepared Tx).
                    1. interesting
                    2. My questions
                        1. Write doing this is not likely to be correct. It breaks the condition check of prepared Tx.
                           Doing so is not actually serializable.
                           Or, only feasible because this paper's Tx is separating read Tx and write Tx cannot mix.
                            1. OK .. the paper noticed the problem. A write Tx also supports condition check, rather than blind write.
                2. Individual write can be committed if an item has prepared for a transaction but OK to overwrite.
                3. An item can prepare for more than one transactions, given they can commit in order, without violating condition checks.
                    1. Anyway, these optimizations are doing write overwrites, leveraging no MVCC is needed
        n. My questions
            1. Seems long running transactions are not supported yet
            2. Can TransactWriteItems include snapshot read? Otherwise how can read-write Tx be serializable?
                1. This is biggest problem from truly doing serializable
            3. No MVCC means read transaction can conflict with write transaction. How bad is it?
    n. Related materials
        1. [è¯‘] [è®ºæ–‡] Dynamo: Amazon's Highly Available Key-value Storeï¼ˆSOSP 2007ï¼‰
           https://zhuanlan.zhihu.com/p/374807359

13. Dayu: Fast and Low-interference Data Recovery in Very-large Storage Systems    [2019, 15 refs, ATC19, Alibaba]
    https://www.usenix.org/conference/atc19/presentation/wang-zhufan
    1. Interesting. Timeslot-based scheduling - drop the task if current timeslot doesn't have enough bandwidth.
       Build the convex hull to use binary search rather than scanning all the nodes which are too many.
       Evaluated on Pangu traces. 2.96x recovery speed faster than Pangu-slow, same recovery speed with Pangu-fast but lower latency.
    2. Highlights
        1. Alibaba production observation
            1. 3500 nodes in our observed cluster
            2. Every node stores 250K chunks on average
            3. Replicas of lost chunks are distributed unevenly among other nodes
            4. Recovery should adjust with foreground traffic
            5. Recovery should handle stagger nodes
        2. Dayu solution - recovery scheduler to be fast and high quality
            1. Centralized scheduler
            2. Timeslot-based scheduling
                1. gather latest info to schedule tasks
                2. overlapping timeslots
            3. Algorithm in one timeslot
                1. Bucket convex hull optimization to choose the source and destination
                    1. minimized (Accumulated size + task size) / node bandwidth - expected finish time.
                    2. choose from 2 candidates, the power of randomly two choices.
                    3. if the current timeslot doesn't have enough bandwidth, drop the task to the next.
                    4. Problem - too many nodes to scan them all
                        1. Build the convex hull, then find the best node on convex shell through binary search
                2. Underemployed node recognition to adjust the task priority
                3. iterative WSS algorithm to assign bandwidth (WSS - weighted shuffle scheduling)
                    1. WSS - Managing Data Transfers in Computer Clusters with Orchestra
                4. Heuristic algorithm to minimize the cost of re-scheduling stragglers
        3. Others
            1. Figure 1(c), 2(d). Use CoV to measure foreground traffic imbalance and churn.
            2. Figure 1(e), size of chunks are mostly 20GB to 40GB.
            3. Implemented by modifying Pangu MetaServer, RootServer, ChunkServer. and Introduced ObServer for global information.
               Testbed on 1000-node cluster deployed Pangu-based Dayu.
    n. Related materials
        1. WSS: Orchestra: Managing Data Transfers in Computer Clusters with Orchestra    [2011, 801 refs]
           https://www.mosharaf.com/wp-content/uploads/orchestra-sigcomm11.pdf
            0. As referenced in the parent paper
                1. "The key idea of WSS is that, to finish all the pairwise transfers at the same time, it guarantees that 1) transfer rates are proportional to data sizes for each transfer, and 2) at least one link is fully utilized."
                2. Dayu's improvement is to make WSS iterative, so that over multiple iterations, so that bottleneck links adapt and even out.
            1. Introduced ITC to manage data transfer in Spark or MapReduce-like framework.
            2. Highlights
                1. Inter-Transfer Controller (ITC)
                2. WSS
                    1. Each transfer pair is assigned a speed Î» = data size / transfer time. So that all pairs finish transfer at the same time. Only one pair bandwidth is fully utilized.
                    2. WSS schedule must finish at least as fast as the progressive filling schedule, making it an optimal solution for shuffle scheduling

14. Presto: A Decade of SQL Analytics at Meta    [2023, 0 refs, Facebook, SIGMOD23]
    https://research.facebook.com/publications/presto-a-decade-of-sql-analytics-at-meta/
    1. Good and comprehensive. Years of Presto improvement and experience on latency/scalability and integration with Spark.
       Caching, vectorized execution, filtering and join, materialized views,
       multi-coordinator, Recoverable grouped execution, spark integration, spilling,
       cost-Based Optimizer, history-based optimizer, Adaptive execution
       Mutable delta data, UDT, UDF, graph extensions.
    2. Highlights
        1. See the attached article
    n. Related materials
        1. [SIGMOD-2023] Presto: A Decade of SQL Analytics at Meta - æ°´æœ¨æ¸…æ‰¬
           https://zhuanlan.zhihu.com/p/649803696
            1. Presto æ˜¯ä¸€ä¸ªå¼€æºåˆ†å¸ƒå¼SQLæŸ¥è¯¢å¼•æ“ï¼Œ2013å¹´åœ¨Metaæ¨å‡ºï¼Œå¹¶äº2019å¹´æèµ ç»™LinuxåŸºé‡‘ä¼šã€‚åœ¨è¿‡å»åå¹´ä¸­ï¼Œéšç€ Meta æ•°æ®é‡çš„è¶…é«˜é€Ÿå¢é•¿ä»¥åŠæ–°çš„ SQL åˆ†æè¦æ±‚ï¼Œå¦‚ä½•ä¿æŒæŸ¥è¯¢å»¶è¿Ÿå’Œå¯æ‰©å±•æ€§ç»™ Presto å¸¦æ¥äº†å·¨å¤§æŒ‘æˆ˜ã€‚Prestoåšäº†ä¸€äº›é‡è¦çš„ä¼˜åŒ–ï¼Œå¦‚åˆ†çº§ç¼“å­˜ã€nativeå‘é‡åŒ–æ‰§è¡Œå¼•æ“ã€ç‰©åŒ–è§†å›¾å’ŒPresto on Sparkã€‚
            2. å› æ­¤prestoæå‡ºäº†æ–°çš„æ¶æ„ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œåˆ†ä¸ºäº†ä¸¤ç§é›†ç¾¤
                1. åŸå§‹prestoæ¶æ„ï¼Œä½†ï¼ˆ1ï¼‰é‡‡ç”¨å¤šä¸ªCoordinatoré¿å…å•ç‚¹æ•…éšœã€‚ï¼ˆ2ï¼‰ä½¿ç”¨nativeå‘é‡åŒ–æ‰§è¡Œå¼•æ“æé«˜æ€§èƒ½ã€‚ï¼ˆ3ï¼‰data cache on flashé¿å…IOç“¶é¢ˆã€‚ï¼ˆ4ï¼‰å…¶å®ƒæ”¹è¿›
                2. Sparkä¸Šçš„prestoï¼Œåˆ©ç”¨Sparkåšruntimeï¼Œprestoä½œä¸ºevaluation libraryæé«˜æ‰©å±•æ€§ã€‚
                3. è¿˜æœ‰ä¸€äº›å…¶å®ƒçš„æ”¹è¿›
                    1. æ”¯æŒç‰©åŒ–è§†å›¾æ¥æé«˜æŸ¥è¯¢æ€§èƒ½å’Œæ•°æ®å¯å˜æ€§
                    2. æ”¯æŒå°†å†…å­˜ä¸­çš„æ•°æ®æº¢å‡ºåˆ°ä¸´æ—¶å­˜å‚¨ä¸­ä»¥å…‹æœå†…å­˜é™åˆ¶ï¼ˆSpillï¼‰ã€‚
                    3. åŸå§‹prestoæ¶æ„æ”¯æŒç‰©åŒ–ä¸­é—´ç»“æœï¼Œä»¥æé«˜recoverabilityã€‚
                    4. å¼•å…¥äº†é¢å¤–çš„å…ƒæ•°æ®ã€‚Type storeç”¨äºæ”¯æŒç”¨æˆ·å®šä¹‰çš„ç±»å‹ï¼Œfunction storeç”¨äºæ”¯æŒsql functionçš„ç¼–å†™å’Œevaluationï¼Œstatistics storeç”¨äºæ›´å¥½çš„ä¼˜åŒ–å†³ç­–ï¼Œremote functionsç”¨äºè¿è¡Œuser-defined functionsã€‚
            3. Latency Improvements
                1. Caching
                    1. prestoå¼•å…¥äº†ä¸åŒçº§åˆ«çš„ç¼“å­˜
                        1. Raw Data Cache
                        2. Fragment Result Cache
                        3. Metadata Cache and Catalog Servers
                    2. Cache locality
                        1. ä¸ºäº†æœ€å¤§é™åº¦æé«˜ç¼“å­˜å‘½ä¸­ç‡ï¼ŒCoordinatorä½¿ç”¨å“ˆå¸Œå‡½æ•°å°†åŒä¸€æ–‡ä»¶çš„è¯»å–è¯·æ±‚è°ƒåº¦ç»™åŒä¸€ä¸ªworkerï¼Œä¸ºäº†é¿å…å‡ºç°çƒ­ç‚¹workerï¼Œè°ƒåº¦å™¨å¯èƒ½ä¼šå›é€€åˆ°ç¬¬äºŒé€‰æ‹©çš„workerä¸Šï¼Œæˆ–åœ¨å¿…è¦æ—¶è·³è¿‡ç¼“å­˜ã€‚
                        2. æŸ¥è¯¢è·¯ç”±ä¸Šä¹Ÿæœ‰ç›¸åŒçš„é€»è¾‘ï¼Œç”±äºprestoåœ¨å…¨çƒå¤šä¸ªæ•°æ®ä¸­å¿ƒéƒ¨ç½²ï¼Œè·¯ç”±å™¨ä¼šå°†æŸ¥è¯¢é‡å®šå‘åˆ°æ‹¥æœ‰ç¼“å­˜æ•°æ®çš„é›†ç¾¤ä¸Šï¼ŒåŒæ—¶å°†hotspot preventionä½œä¸ºfallback
                2. Native vectorized execution
                    1. Veloxæ˜¯Metaä½æ”¯æŒC++å‘é‡åŒ–æ‰§è¡Œè€Œä»prestoå­µåŒ–å‡ºçš„ä¸€ä¸ªé¡¹ç›®ï¼Œåæ¥æˆä¸ºäº†ä¸€ä¸ªé€šç”¨çš„å‘é‡åŒ–æ‰§è¡Œåº“ã€‚
                3. Adaptive filtering
                    1. Subfield Pruning
                        1. ç°ä»£æ•°æ®ä»“åº“ä¸­å¹¿æ³›ä½¿ç”¨mapã€arrayã€structç­‰å¤æ‚ç±»å‹ç»“æ„ï¼Œä¸ºäº†æé«˜CPUæ•ˆç‡ï¼Œéœ€è¦åœ¨ä¸è¯»å–æ•´ä¸ªå¤æ‚å¯¹è±¡çš„æƒ…å†µä¸‹æœ‰æ•ˆæå–å­å­—æ®µã€‚Prestoæ”¯æŒå­å­—æ®µå‰ªæï¼Œå‘readerå‘é€æ‰€éœ€çš„å¤æ‚å¯¹è±¡çš„ç´¢å¼•æˆ–keyçš„ä¿¡å·ã€‚
                    2. Filter recordering
                        1. æœ‰äº›filterèƒ½åœ¨æ›´å°‘çš„CPU cycleä¸­åˆ é™¤æ›´å¤šçš„è¡Œã€‚æ‰€ä»¥Prestoä¼šè‡ªåŠ¨é‡æ’åºfilterï¼Œä½¿é€‰æ‹©æ€§æ›´å¼ºçš„filteræ’åœ¨å‰é¢ã€‚
                    3. Filter-based lazy materialization
                        1. æŒ‰é¡ºåºåº”ç”¨ä¸€ç»„filteræ—¶ï¼ŒPrestoä¼štracké‚£äº›æ»¡è¶³filterè°“è¯çš„è¡Œï¼Œé‚£äº›ä¸æ»¡è¶³çš„è¡Œå°±ä¸éœ€è¦å†è¿‡åé¢çš„filteräº†ã€‚æ¯”å¦‚ç°åœ¨æœ‰ä¸¤ä¸ªfilterï¼Œåˆ†åˆ«ä¸ºcol1 > 10 and col2 = 5ï¼Œå…ˆè¿ç®—col1çš„è¡¨è¾¾å¼ï¼Œcol1æ˜¯å¿…é¡»ç‰©åŒ–çš„ï¼Œä½†æ˜¯åªæœ‰é€šè¿‡col1>10 çš„è¡Œæ‰éœ€è¦ç‰©åŒ–col2.
                    4. Dynamic join filtering
                        1. æ¯”å¦‚å¯¹äºinner joinï¼Œé€šè¿‡buildç«¯æ•°æ®æä¾›èƒ½ä»£è¡¨ç®€æ˜“â€œæ‘˜è¦â€çš„bloom filters/ranges/distinct valuesä½œä¸ºfilterä¸‹æ¨ç»™probeç«¯ã€‚
                        2. è¿™é‡Œå¦å¤–è¯´ä¸€ä¸‹ï¼Œè¿™é‡Œçš„dynamic join filteringä¹Ÿå¯ä»¥ç§°ä¸ºruntime filterï¼Œåœ¨ä¸€äº›ç³»ç»Ÿé‡Œå«dynamic filterï¼Œå…¶æ ¸å¿ƒæ€æƒ³ä¸»è¦æ˜¯ç”¨äºHashJoinä¸­ï¼Œä½¿ç”¨buildç«¯æ„å»ºä¸€ä¸ªè½»é‡çš„filterï¼Œä¸‹æ¨ç»™probeç«¯ï¼Œå¯ä»¥é€šè¿‡buildç«¯çš„rangeä¿¡æ¯å’Œchunkçš„ç»Ÿè®¡ä¿¡æ¯ç›´æ¥è¿‡æ»¤æ‰chunkèŠ‚çœIOï¼Œä¹Ÿå¯ä»¥è¿‡æ»¤æ¯è¡Œæ•°æ®ï¼Œå› ä¸ºfilterè¾ƒä¸ºè½»é‡ï¼Œè¿‡æ»¤åº¦è¾ƒå¥½æƒ…å†µä¸‹å¯ä»¥å‡å°‘CPUå¼€é”€ï¼Œä¹Ÿå¯ä»¥å‡å°‘åç»­å¯èƒ½éœ€è¦shuffleçš„ç½‘ç»œå¼€é”€ã€‚é™¤äº†ç”¨äºHashJoiné‡Œï¼Œä¹Ÿè¿˜æœ‰ä¸€äº›å…¶å®ƒåœºæ™¯å¯ä»¥ä½¿ç”¨ã€‚
                            1. Good.
                5. Materialized views and near real-time data
                    1. å½“å‰å­˜åœ¨çš„é—®é¢˜ï¼šç”¨æˆ·è¾ƒå°‘ä½¿ç”¨åŸå§‹æ•°æ®æ¥æ„å»ºdashboardsï¼Œå› ä¸ºåŸå§‹æ•°æ®é€šå¸¸éå¸¸å¤šï¼Œæ— æ³•æä¾›ä½å»¶è¿Ÿçš„ä½“éªŒã€‚äººä»¬å€¾å‘äºé€šè¿‡é¢„è®¡ç®—è¡¨æ¥æå‰å‡å°‘åŸºæ•°ï¼Œä½†æ˜¯è¿™ç§æ–¹æ³•ä¸é€‚ç”¨äºNRTï¼ˆnear real-timeï¼‰å®ä¾‹ï¼Œå› ä¸ºæ•°æ®æ˜¯è¿ç»­ä¸æ–­å˜åŒ–çš„ã€‚
                    2. å› æ­¤ï¼Œprestoæä¾›äº†ç‰©åŒ–è§†å›¾çš„åŠŸèƒ½ï¼Œç‰©åŒ–è§†å›¾æ˜¯ç”±æŸ¥è¯¢è¡¨ç¤ºçš„è§†å›¾ï¼Œå…¶ç»“æœè¢«å­˜å‚¨èµ·æ¥ã€‚
                        1. ç‰©åŒ–è§†å›¾æ›´æ–°ï¼šå½“prestoåˆ›å»ºä¸€ä¸ªç‰©åŒ–è§†å›¾æ—¶ï¼Œä¼šåˆ›å»ºä¸€ä¸ªautomatic jobæ¥ä¸ºè¯¥è§†å›¾ç‰©åŒ–æ•°æ®ã€‚åªè¦åŸºç¡€è¡¨çš„æŸäº›å•ä½ï¼ˆé€šå¸¸æ˜¯å°æ—¶æˆ–å¤©ï¼‰å˜å¾—ä¸å¯å˜ï¼Œautomatic jobå°±ä¼šè¿è¡Œè§†å›¾æŸ¥è¯¢æ¥ç‰©åŒ–è§†å›¾çš„æ•°æ®ã€‚
                        2. ç‰©åŒ–è§†å›¾æŸ¥è¯¢ï¼šå½“ç”¨æˆ·æŸ¥è¯¢ç‰©åŒ–è§†å›¾æ—¶ï¼Œprestoä¼šå°†ç‰©åŒ–æ•°æ®çš„æŸ¥è¯¢å’Œéç‰©åŒ–æ•°æ®çš„æŸ¥è¯¢union allèµ·æ¥ï¼Œè¿™æ ·ï¼Œç”±äºæ•°æ®é‡å‡å°‘ï¼ŒæŸ¥è¯¢æ—¢èƒ½ä¿è¯fressnessåˆèƒ½é™ä½å»¶è¿Ÿ
            4. Scalability Improvements
                1. Prestoæ”¹è¿›äº†æ¶æ„ï¼Œé›†æˆäº†å„ç§æ”¹è¿›ä»¥å¤„ç†å•ç‚¹æ•…éšœã€worker crashã€æ•°æ®å€¾æ–œã€å†…å­˜é™åˆ¶ç­‰é—®é¢˜ã€‚
                2. Multiple Coordinators
                    1. Prestoé€šè¿‡separatingæŸ¥è¯¢å’Œé›†ç¾¤çš„ç”Ÿå‘½å‘¨æœŸæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚Coordinatoråªæ§åˆ¶æŸ¥è¯¢çš„ç”Ÿå‘½å‘¨æœŸï¼Œæ–°å¼•å…¥çš„Resource managersè´Ÿè´£é›†ç¾¤çš„é˜Ÿåˆ—å’Œèµ„æºåˆ©ç”¨ç‡ç›‘æ§ï¼Œå…¶æ¶æ„å¦‚ä¸Šå›¾æ‰€ç¤ºã€‚
                    2. Coordinatorå®šæœŸä»resource managersè·å–æ’é˜Ÿä¿¡æ¯ï¼Œä»¥å†³å®šæ‰§è¡Œå“ªäº›æŸ¥è¯¢ï¼Œæˆ–è€…é˜Ÿåˆ—ä¸­æŸ¥è¯¢ä¼˜å…ˆçº§è¾ƒä½ï¼Œå¯ä»¥æ‰§è¡Œä¸€ä¸ªæ–°æäº¤çš„æŸ¥è¯¢ï¼Œä»¥é¿å…æ’é˜Ÿå¼€é”€æˆ–ç½‘ç»œè·³è½¬å»¶è¿Ÿã€‚
                3. Recoverable grouped execution
                    1. é—®é¢˜ï¼š1. ä¸èƒ½æ‰©å±•å†…å­˜é™åˆ¶ï¼Œ2. ä¸èƒ½å¯é ä¿è¯workerä¸ä¼šå´©æºƒ
                    2. å¦‚æœè¡¨æ‰«æåçš„ç¬¬ä¸€ä¸ªèšåˆ/è¿æ¥/çª—å£å‡½æ•°çš„keyæ˜¯æ•°æ®åˆ†åŒºkeyçš„è¶…é›†ï¼ŒæŸ¥è¯¢å°±èƒ½ä»¥â€œåˆ†ç»„â€æ–¹å¼æ‰§è¡Œï¼ŒæŸ¥è¯¢æ—¶ä¼šé€ä¸ªå¯¹åˆ†åŒºè¿›è¡Œæ‰«æï¼Œå¦‚æœå‘ç°å†…å­˜è¶…å‡ºé™åˆ¶ï¼Œå°±ä¼šæ‰§è¡Œåˆ†ç»„æŸ¥è¯¢ä»¥é™ä½å³°å€¼å†…å­˜æŸè€—ã€‚
                4. Presto on Spark
                    1. Presto on Sparkæ¶æ„ç”¨Sparkå–ä»£äº†prestoå†…ç½®çš„è°ƒåº¦å™¨ã€æ´—ç‰Œã€èµ„æºç®¡ç†å’Œä»»åŠ¡æ‰§è¡Œ
                    2. Prestoçš„Coordinatorå’Œworkerç­‰prestoæœåŠ¡éƒ½æ˜¯libraryï¼Œå®ƒä»¬ä¹‹é—´ä¸ä¼šäº’ç›¸é€šä¿¡ï¼Œä¹Ÿä¸ä¼šç®¡ç†å†…å­˜ã€çº¿ç¨‹æˆ–ç½‘ç»œã€‚ä¸ºäº†ç®€åŒ–ï¼Œè¿™äº›æ–¹é¢éƒ½ä»åº“ä¸­ç§»é™¤ï¼Œå§”æ‰˜ç»™äº†sparké›†ç¾¤ã€‚
            5. Efficiency Improvements
                1. Cost-based optimizer
                2. History-based optimizer
                    1. ç”±äºMetaçš„ETLå·¥ä½œå¤§é‡ä½¿ç”¨Prestoï¼Œå› æ­¤æŸ¥è¯¢å…·æœ‰é«˜åº¦é‡å¤æ€§å’Œå¯é¢„æµ‹æ€§ï¼ŒåŸºäºå†å²è®°å½•çš„ä¼˜åŒ–å™¨çš„ç†å¿µæ˜¯åˆ©ç”¨ä¹‹å‰å®Œæˆçš„é‡å¤æŸ¥è¯¢çš„ç²¾ç¡®æ‰§è¡Œç»Ÿè®¡æ•°æ®æ¥æŒ‡å¯¼æœªæ¥é‡å¤æŸ¥è¯¢çš„è§„åˆ’
                    2. Interesting
                3. Adaptive execution
                    1. å¦‚æœåœ¨è¿è¡ŒæœŸé—´æ‰§è¡Œè®¡åˆ’ä¸æ˜¯æœ€ä¼˜çš„ï¼Œå°±éœ€è¦è‡ªé€‚åº”æ‰§è¡Œæ¥åŠ¨æ€è°ƒæ•´æŸ¥è¯¢è®¡åˆ’ã€‚è‡ªé€‚åº”æ‰§è¡Œåˆ©ç”¨å·²å®Œæˆçš„ä»»åŠ¡å‘CoordinatoræŠ¥å‘Šç»Ÿè®¡æ•°æ®ï¼Œä»¥ä¾¿Coordinatoråˆ©ç”¨è¿™äº›æ•°æ®ä¸ºä¸‹æ¸¸ä»»åŠ¡é‡æ–°ä¼˜åŒ–è®¡åˆ’ã€‚
                    2. ä¸ºäº†åˆ©ç”¨è¿è¡Œæ—¶ç»Ÿè®¡æ•°æ®ï¼Œè°ƒåº¦å™¨ä¼šåˆ†é˜¶æ®µè°ƒåº¦ä»»åŠ¡ï¼Œä»æ‰«æä»»åŠ¡ä¸€ç›´åˆ°rootï¼Œå½“ä¸Šæ¸¸ä»»åŠ¡å®Œæˆåï¼Œä¼˜åŒ–å™¨å°†æ ¹æ®æ–°æ”¶é›†çš„ç»Ÿè®¡æ•°æ®é‡æ–°è®¡åˆ’ï¼Œå¹¶æ ¹æ®æ–°è®¡åˆ’è°ƒåº¦ä¸‹æ¸¸ä»»åŠ¡ã€‚
            6. Enable Richer Analytics
                1. é™¤äº†æ”¹è¿›åˆ†æå‹å·¥ä½œè´Ÿè½½çš„å»¶è¿Ÿã€å¯æ‰©å±•æ€§å’Œæ•ˆç‡å¤–ï¼ŒMeta è¿˜è¶Šæ¥è¶Šå€¾å‘äºå¼ºè°ƒæœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹user casesï¼Œå¢åŠ å¯¹éšç§è¦æ±‚å’Œå›¾å½¢åˆ†æçš„æ”¯æŒã€‚
                    1. ä»¥æœºå™¨å­¦ä¹ å’Œéšç§ä¸ºé‡ç‚¹çš„éœ€æ±‚ä¸æ–­å¢é•¿ï¼Œå·²é€æ¸å°†ä¼ ç»Ÿçš„ä»¥åˆ†æä¸ºé‡ç‚¹çš„æ•°æ®ä»“åº“è½¬å˜ä¸ºæ›´åŠ å¼€æ”¾å’Œçµæ´»çš„â€œæ•°æ®æ¹–â€è®¾ç½®ã€‚åˆ†ææ•°æ®ä¸å†æ˜¯ä¸€æˆä¸å˜çš„ã€‚Metaéœ€è¦èƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„éšç§é€‰æ‹©åˆ é™¤ç”¨æˆ·æ•°æ®ã€‚åœ¨æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹ä¸­ï¼Œå¯ä»¥çµæ´»æ·»åŠ columnsä»¥å°è¯•ä¸åŒçš„å€™é€‰ç‰¹å¾ã€‚
                2. Handling mutability
                    1. æ•°æ®ä»“åº“å†æ¥åªæ”¯æŒä¸å¯å˜æ•°æ®ï¼Œè¿‘å‡ å¹´ï¼Œå¯å˜æ•°æ®æ”¯æŒç‰ˆæœ¬æ§åˆ¶çš„è¶‹åŠ¿è¶Šæ¥è¶Šæ˜æ˜¾ã€‚
                    2. Prestoå†…ç½®äº†Deltaï¼Œå…è®¸è¡¨çš„å˜åŒ–ï¼Œå¯ä»¥çµæ´»åœ°æ·»åŠ æˆ–ç§»åŠ¨åˆ—æˆ–è¡Œã€‚Presto è¯»å–ä¸»æ–‡ä»¶æ—¶ï¼Œä¼šå¯åŠ¨é¢å¤–çš„è¯»å–å™¨æ¥åˆå¹¶è¿™äº›deltaæ–‡ä»¶ï¼Œä»¥åæ˜ å˜åŒ–ã€‚delta æ–‡ä»¶çš„å…³è”å’Œé¡ºåºä¿å­˜åœ¨å…ƒæ•°æ®å­˜å‚¨ä¸­ï¼Œå¹¶è¿›è¡Œç‰ˆæœ¬æ§åˆ¶ã€‚
                3. User-defined types
                    1. ä¾‹å¦‚ï¼Œå¯ä»¥æ ¹æ® Long ç±»å‹å®šä¹‰ ProfileId ç±»å‹ï¼Œå¹¶å°† UserId å’Œ PageId ç±»å‹ä½œä¸ºå…¶å­ç±»å‹ã€‚ç”¨æˆ·å®šä¹‰çš„ç±»å‹å®šä¹‰å­˜å‚¨åœ¨è¿œç¨‹å…ƒæ•°æ®å­˜å‚¨åŒºä¸­ã€‚
                    2. è¿˜å¯ä»¥å°†é¢å¤–ä¿¡æ¯ä¸ç”¨æˆ·å®šä¹‰çš„ç±»å‹å…³è”èµ·æ¥ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡ SQL è¡¨è¾¾å¼è¡¨è¾¾çš„çº¦æŸæ¡ä»¶ã€‚è¿™æ ·å°±å¯ä»¥åœ¨è¿è¡Œæ—¶è¿›è¡Œæ•°æ®è´¨é‡æ£€æŸ¥ã€‚ä¾‹å¦‚ï¼Œç”¨æˆ· ID ä¸èƒ½æ˜¯è´Ÿæ•´æ•°æˆ–è¶…è¿‡ä¸€å®šé•¿åº¦ã€‚
                4. User-defined functions
                    1. In-process UDFï¼šå‡½æ•°ä»¥libraryçš„å½¢å¼ç¼–å†™å’Œå‘å¸ƒï¼Œprestoåœ¨è¿è¡Œæ—¶åŠ è½½libraryï¼Œå¹¶åœ¨ä¸main evaluation engineç›¸åŒçš„è¿›ç¨‹ä¸Šæ‰§è¡Œã€‚
                    2. UDF serviceï¼šä¸ºäº†æ”¯æŒå¤šç§Ÿæˆ·æ¨¡å¼æˆ–ä¸åŒç¼–ç¨‹è¯­è¨€ä¸­çš„UDFï¼Œprestoæ„å»ºäº†UDF serviceï¼Œè¿™äº›å‡½æ•°é€šè¿‡prestoé›†ç¾¤çš„RPCåœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šè°ƒç”¨ã€‚
                    3. ç”±äºä¸€ä¸ªè¡¨è¾¾å¼æ—¢å¯ä»¥åŒ…å«æœ¬åœ°å¯æ‰§è¡Œå‡½æ•°ï¼Œä¹Ÿå¯ä»¥åŒ…å«è¿œç¨‹UDFï¼Œå› æ­¤åœ¨ç¼–è¯‘æ—¶ï¼Œè¡¨è¾¾å¼å°†è¢«åˆ†è§£ä¸ºæœ¬åœ°å¯æ‰§è¡Œå’Œè¿œç¨‹å¯æ‰§è¡Œã€‚
                    4. SQL functionsï¼šè™½ç„¶UDFå…·æœ‰çµæ´»æ€§ï¼Œä½†å‡ºäºå®¡è®¡å’Œéšç§ä¿æŠ¤çš„ç›®çš„ï¼ŒæŸ¥è¯¢å¿…é¡»èƒ½å¤Ÿè¢«â€œreasonedâ€ï¼Œä¸èƒ½æœ‰é»‘ç®±çš„æ‰§è¡Œã€‚å½“å‡½æ•°é€»è¾‘å¯ä»¥ç”¨SQLè¡¨è¾¾æ—¶ï¼Œå…è®¸ç”¨æˆ·å®šä¹‰SQLå‡½æ•°
                5. Graph extensions
                    1. å›¾æŸ¥è¯¢ä¼šè¢«è§£æä¸ºä¸€ä¸ªç‰¹æ®Šçš„å›¾é€»è¾‘è®¡åˆ’ï¼Œç„¶ååˆ©ç”¨å›¾æŸ¥è¯¢çš„è¯­ä¹‰å¯¹å…¶è¿›è¡Œä¼˜åŒ–ã€‚æœ€ç»ˆï¼Œä¼˜åŒ–åçš„å›¾é€»è¾‘è®¡åˆ’è¢«è½¬æ¢ä¸ºå…³ç³»è®¡åˆ’ï¼Œå¹¶åƒå…¶ä»– Presto æŸ¥è¯¢ä¸€æ ·æ‰§è¡Œã€‚
                    2. Multi-step executionï¼šåƒä¸Šå›¾ä¸­è¿™æ ·çš„ç®€å•æŸ¥è¯¢ä¼šè½¬åŒ–ä¸ºå…³ç³»æŸ¥è¯¢ï¼Œå…¶è¿æ¥æ¬¡æ•°ä¸è·¯å¾„çš„æœ€å¤§é•¿åº¦ç›¸åŒã€‚è¿™ç§æŸ¥è¯¢å¯èƒ½ä¼šè¾¾åˆ° Presto çš„å†…å­˜é™åˆ¶ï¼Œå°¤å…¶æ˜¯å½“æœ‰å¤ªå¤šçš„è·¯å¾„éœ€è¦è®¡ç®—æ—¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œprestoå®ç°äº†ä¸€ç§ä¼˜åŒ–æ–¹æ³•ï¼Œå°†å›¾æŸ¥è¯¢è®¡åˆ’è½¬åŒ–ä¸ºä¸€ç³»åˆ—è¾ƒå°çš„ Presto æŸ¥è¯¢è®¡åˆ’ã€‚æ¯ä¸ªè¾ƒå°çš„æŸ¥è¯¢è®¡åˆ’éƒ½ä¼šè®¡ç®—ä¸€å®šé•¿åº¦çš„è·¯å¾„ï¼Œå¹¶å°†å…¶å­˜å‚¨åˆ°ä¸´æ—¶ä¸­é—´è¡¨ä¸­ï¼Œç„¶åç»§ç»­æ‰©å±•è·¯å¾„ã€‚è¿™æ ·ï¼Œæ¯æ¬¡è¿­ä»£éƒ½ä¸ä¼šè¶…å‡ºå†…å­˜é™åˆ¶ã€‚
                    3. Efficient path extensionï¼šè¿˜æ˜¯çœ‹ä¸Šå›¾ï¼Œä¸€ä¸ªç®€å•çš„è®¡åˆ’ä¼šè®¡ç®—é•¿åº¦ä¸º 1ã€2 ç­‰çš„è·¯å¾„ï¼Œå¹¶å¯¹å®ƒä»¬è¿›è¡Œ UNION ALLã€‚è¿™å°†å¯¼è‡´å†—ä½™è®¡ç®—ã€‚è®¡ç®—é•¿åº¦ä¸º çš„è·¯å¾„æ‰€éœ€çš„å·¥ä½œé‡ä¸è®¡ç®—é•¿åº¦ä¸º - 1 çš„è·¯å¾„ç›¸åŠ ä¸Šå°†å®ƒæ‰©å±•ä¸ºé•¿åº¦ä¸º çš„è·¯å¾„ç›¸åŒã€‚
                    4. Efficient subgraph computationï¼šåªéœ€è¦è·Ÿè¸ªå·²è®¿é—®è¿‡çš„è¾¹ã€‚è¿™æ ·ï¼Œå­å›¾è®¡ç®—è§„åˆ’å°±å¯ä»¥ä»å­˜å‚¨ä¸­æ‰«æä¸€æ¬¡edge tableï¼Œç„¶ååœ¨å¯ä»¥æ‰©å±•çš„æƒ…å†µä¸‹å°†è¾¹æ ‡è®°ä¸ºå·²è®¿é—®è¿‡ï¼Œä»è€Œæœ€å¤§é™åº¦åœ°å‡å°‘ IOã€‚
                    5. Complex filter pushdownï¼šç„¶è€Œï¼Œå›¾è¯­ä¹‰ä¿¡æ¯å…è®¸åœ¨æ¯æ¬¡è¿æ¥åç›´æ¥å‘ä¸‹æ¨é€è¿™äº›è¿‡æ»¤å™¨ï¼Œæ¯ä¸ªè¿‡æ»¤å™¨éƒ½ä¼šè®¡ç®—ä¸‹ä¸€è·³ï¼Œä»è€Œæœ€å¤§é™åº¦åœ°å‡å°‘è®¡ç®—çš„ä¸­é—´è·¯å¾„æ•°é‡ã€‚
            7. Performance in Production
                1. P75 is ~3 seconds. P90 is ~10 seconds. No change with fast growth of data.
                2. Presto on Spark usage is new but fast growing

15. Shared Foundations: Modernizing Meta's Data Lakehouse    [2023, 7 refs, CIDR DB]
    https://research.facebook.com/publications/shared-foundations-modernizing-metas-data-lakehouse/
    https://www.youtube.com/watch?v=wyOTpcYrEF0
    1. Generational leap in the data infrastructure landscape. Open formats, consolidating languages, engines: CoreSQL, Velox, Presto
    2. Highlights
        1. Background
            1. Usage Trends
                1. Data Explosion
                2. Machine Learning
                3. Freshness and Latency
                4. External Analytics
                5.  Complex Data Models
                6. Richer Query Methods
            2. Environmental Trends
                1. Disaggregation
                2. Horizontal Scaling
                3. Elastic Compute
                4. Power Efficiency
                5. Global Optimization
                6. Engineering Efficiency
            3. The problem: Fragmentation
                1. Layer
                    1. Language
                    2. Distribution/Runtime
                    3. Execution
                    4. Data Access
                2. Scope
                    1. SQL dialects, functions, entity & type metadata
                    2. Distributed execution, shuffle, resource management
                    3. Evaluation at node, caching
                    4. Formats, storage disaggregation
                3. Challenges
                    1. SQL dialect fragmentation, lack if expressibility
                    2. Scalability, Efficiency, Fragmentation
                    3. Latency, efficiency, Java / C++, dialect fragmentation
                    4. Library fragmentation, not data driven, poor encodings
        2. Solution: Open Data Lakehouse Analytics
            1. Direct data access
                1. Disaggregated storage
                2. Open file formats
                3. Open metadata APIs
            2. Diverse applications
                1. Batch
                2. Interactive
                3. Streaming
                4. Machine Learning
            3. Consolidation
                1. Language consolidation
                    1. PrestoSQL -> CoreSQL
                2. Execution consolidation 
                    1. Velox
                3. Engine consolidation
                    1. Presto -> RaptorX -> Prestissimo
                        1. Presto running on Velox
                    2. Presto on Spark
                    3. Stream Processing - XStream
                        1. CoreSQL
                        2. Velox for execution
                    4. Machine Learning
                        1. File format inefficiencies -> Alpha
                            1. make available via Velox

16. Towards Building Autonomous Data Services on Azure    [2023, 2 refs]            
    https://pages.cs.wisc.edu/~yxy/cs839-f23/slides/L17-2-auto-azure.pdf
    1. Highlights
        1. What is an autonomous data service?
            1. improving ease of use, optimizing performance, reducing costs, and maintaining data privacy
            2. layers
                1. Cloud Infrastructure layer
                2. Query engine layer
                    1. queries and jobs are often recurrent and similar
                3. Service layer
    n. Related materials
        1. SIGMOD 2023 æœ‰å“ªäº›å€¼å¾—å…³æ³¨çš„è®ºæ–‡ï¼Ÿ - Jamesçš„å›ç­”
           https://www.zhihu.com/question/557505628
            1. "Towards Building Autonomous Data Services on Azure. åº”è¯¥æ˜¯ä»Šå¹´sigmodä½œè€…æœ€å¤šçš„çš„æ–‡ç« ï¼Œå…³æ³¨ä¸€ä¸‹å¤§å·¥ä½œã€‚"

17. HQI: High-Throughput Vector Similarity Search in Knowledge Graphs    [2023, 0 refs, Apple]
    https://arxiv.org/abs/2304.01926
    1. Interesting. qd-tree based index for hybrid search (ANN + multiple relational predicts). it transformed vector similarity to relational numbers (k-means centroid id) that can be indexed by qd-tree.
    2. Highlights
        1. Background
            1. Knowledge Graph
            2. Hybrid vector similarity search - ANN with relational field filters
            3. filter commonality and filter stability. and relation predicts relate to query vectors
        3. Workload-aware index for hybrid search
            1. Traditional approach: partition by relational attribute first, and then construct vector index (IVF, HNSW) at each partition
            2. Our solution
                1. query predict attributes can cover multiple attributes
                2. Based on qd-tree, a learned index, and semantic description to each partition.
                    1. semantic description of the qd-tree is simply a bitmap donating which ancestor predict evaluated to true
                3. To work with qd-tree, transform vector similarty and relational attribtues to a uniformed manner
                    1. use k-means to get centroids. each vector is associated with a centroids which is transformed into a number. a query is transformed to matching a group of numbers, where each number is a centroid near to it.
    n. related materials
        1. SIGMOD 2023 æœ‰å“ªäº›å€¼å¾—å…³æ³¨çš„è®ºæ–‡ï¼Ÿ - Jamesçš„å›ç­”
           https://www.zhihu.com/question/557505628
            1. "High-Throughput Vector Similarity Search in Knowledge Graphs. è‹¹æœå¦‚ä½•åšé«˜ç»´å‘é‡æœç´¢ã€‚"
        2. High-Throughput Vector Similarity Search in Knowledge Graphs - Chao.G
           https://zhuanlan.zhihu.com/p/641031533
            1. Background
                1. æ··åˆæŸ¥è¯¢ - åœ¨å‘é‡æ£€ç´¢é¢†åŸŸä¸€èˆ¬è®¤ä¸ºæ˜¯å¸¦ä¸Šå±æ€§è¿‡æ»¤æ¡ä»¶çš„ ANN æŸ¥è¯¢
                2. workload-awareï¼Œä½œè€…å‘ç°åœ¨è¿™ç§çŸ¥è¯†å›¾è°±çš„ workloads ä¸­æ··åˆæŸ¥è¯¢çš„è¿‡æ»¤æ¡ä»¶å…·å¤‡ä¸€å®šè§„å¾‹æ€§ï¼ˆæ–‡ç« ä¸­æ ¹æ®è¿‡æ»¤æ¡ä»¶çš„é€‰æ‹©ç‡åˆ—å‡ºäº† 10 ç§ä½œä¸º filter templateï¼‰
                3. pre-filter å’Œ post-filter
            2. Query Batching
                1. å¯¹äºç›¸åŒè¿‡æ»¤æ¡ä»¶çš„ query å¯ä»¥ group åœ¨ä¸€èµ·
                2. å› ä¸º HQI é‡‡ç”¨çš„æ˜¯ IVF ç±»çš„ç´¢å¼•ï¼Œå¯¹äºè®¿é—®ç›¸åŒ posting list çš„ query å¯ä»¥ group åœ¨ä¸€èµ·ï¼Œåˆ©ç”¨ç¡¬ä»¶å¯¹çŸ©é˜µä¹˜æ³•çš„æ·±åº¦ä¼˜åŒ–

18. Photon: A Fast Query Engine for Lakehouse Systems    [2022, 32 refs, CIDR DB, Databricks]
    https://people.eecs.berkeley.edu/~matei/papers/2022/sigmod_photon.pdf
    https://www.youtube.com/watch?v=TDrIt1RDFqQ
    1. Databricks experience on improving query engine. Spark integration, native C++ and memory management, Interpreted vectorized execution.
    2. Highlights
        1. Background
            1. Lakehouse: performance with data warehouses, and flexibility and open formats like Datalakes
        2. Photon query engine
            1. 100% Apache Spark compatible, built ground up for best performance. ~2x faster than the preceder
            2. Key points
                1. Interpreted vectorized execution model rather than code generation
                    1. Based on MonetDB/X100 system
                2. native code using off-heap memory, JNI no copy
                    1. implement using native C++ rather than Databricks Runtime (DBR) which is based on JVM
                3. integration with Spark UDF
                    1. converting Spark plans to Photon plans
                    2. Photon hooks into Spark's memory manager
                4. querying raw uncurated data
                5. adaptive execution, at batch-level adaptivity
    n. related materials
        1. è®ºæ–‡è§£è¯» Photon: A Fast Query Engine for Lakehouse Systems - zhanglistar
           https://zhuanlan.zhihu.com/p/511400714
            1. "è¿™ç¯‡è®ºæ–‡æ˜¯databrickså…¬å¸é¦–æ¬¡å°†å†…éƒ¨çš„åŸºäºc++çš„nativeæ‰§è¡Œå¼•æ“ç»†èŠ‚å‘è¡¨åœ¨SIGMOD 2022"
            2. Background
                1. "è®ºæ–‡é¦–å…ˆé˜è¿°äº†lakehouseçš„ä½œç”¨ã€‚é¦–å…ˆï¼Œä¼ä¸šä¼šå°†å¤§é‡æ•°æ®å­˜å‚¨åœ¨å¼¹æ€§ã€å¯æ‰©å±•çš„data lakeä¸Šæ¯”å¦‚amazon s3ã€azure data lake storageï¼Œgoogle cloud storageç­‰ï¼Œè¿™äº›æ•°æ®å¯èƒ½æ˜¯ä»¥apache parquetã€orcã€delta lakeç­‰open file formatå­˜å‚¨çš„rawã€uncurated datasetsï¼Œå®¢æˆ·/ç”¨æˆ·å¯ä»¥é€šè¿‡prestoï¼Œsparkç­‰è®¡ç®—å¼•æ“è®¿é—®ï¼Œå·¥ä½œè´Ÿè½½åŒ…æ‹¬BIï¼Œmlç­‰ã€‚

                å…¶æ¬¡ï¼Œä¸ºäº†è·å–æ›´é«˜çš„æ€§èƒ½ã€æ•°æ®æ²»ç†ï¼Œä¼ä¸šä¼šé€šè¿‡ETLæŠŠéƒ¨åˆ†æ•°æ®ä»data lakeä¸Šä¼ è¾“åˆ°data warehouseï¼ˆæ¯”å¦‚apache hive)ä¸­ï¼Œå®é™…è¿™æ˜¯ä¸€ä¸ªä¸¤å±‚çš„å­˜å‚¨æ¶æ„ï¼Œè¿™æ ·å¸¦æ¥çš„æˆæœ¬æ˜¾è€Œæ˜“è§ã€‚

                æ‰€ä»¥ï¼Œå‡ºç°äº†æ‰€ä»¥lakehouseï¼ˆdatabrickçš„äº§å“å°±æ˜¯Delta Lakeï¼‰åŸºäºå¯¹è±¡å­˜å‚¨æ„å»ºäº†data warehouseçš„èƒ½åŠ›ï¼Œæ¯”å¦‚ç»Ÿä¸€çš„æ•°æ®è®¿é—®ã€æ•°æ®æ²»ç†ã€SQLæ”¯æŒç­‰ï¼Œè¿™æ ·çš„å•å±‚æ¶æ„å¯¹äºç”¨æˆ·è®¿é—®æ•°æ®éå¸¸å‹å¥½ã€‚ä¸ºäº†æ›´å¥½çš„æŸ¥è¯¢performanceï¼Œdelta lakeåšäº†ä¸å°‘çš„ä¼˜åŒ–ï¼Œæ¯”å¦‚transactionså’Œtime travelï¼Œdata clusteringå’Œdata skipping indeicesç­‰ã€‚ä½†æ˜¯ä»…ä»…åœ¨å­˜å‚¨å±‚åŠªåŠ›æ˜¯ä¸å¤Ÿçš„ï¼Œè¿˜éœ€è¦åœ¨query engine è¿™å±‚åŠªåŠ›ï¼Œè¿™å°±æ˜¯æœ¬è®ºæ–‡è¦é˜è¿°çš„photonã€‚"
            3. Photonä¸»è¦çš„æŒ‘æˆ˜
                1. "ä¸ä¼ ç»Ÿçš„data warehouseä¸Šçš„æ‰§è¡Œå¼•æ“ä¸åŒï¼Œphotonéœ€è¦è§£å†³æ–°é—®é¢˜ï¼Œå°±æ˜¯rawã€uncurated data(å¯ä»¥ç†è§£ä¸ºä¸è§„åˆ™æ•°æ®ï¼‰ï¼Œå…¶ç‰¹æ€§æ˜¯ï¼šå¯èƒ½å­˜åœ¨æ˜¯highly irregular datasetsï¼Œpoor physical layoutï¼Œlarge fieldsï¼Œno useful clustering or data statisticsï¼Œstringæ¥ä»£è¡¨dateæˆ–è€…intï¼Œæ•°æ®ç¼ºå¤±å€¼ä¸ä¸€å®šç”¨NULLå¡«å……è€Œæ˜¯é»˜è®¤å€¼ç­‰ç­‰ã€‚"
                2. "å¸Œæœ›æ”¯æŒå·²æœ‰çš„sparkï¼Œå¹¶ä¸”è¯­ä¹‰å…¼å®¹ï¼Œè¡¨ç°åœ¨SQLå…¼å®¹å’Œdataframe APIå…¼å®¹ï¼Œä¹Ÿå°±æ˜¯è¯´å¯¹äºä¸Šå±‚ç”¨æˆ·æ¥è®²æ˜¯é€æ˜çš„ã€‚"
                   "å¤§ä½“æ¥è¯´ï¼ŒDatabricksæœ‰ä¸€ä¸ªä»apache spark forkçš„ä¸€ä¸ªdatabricks runtimeï¼ˆDBR)ï¼ŒåŠ å…¥äº†æ›´å¤šçš„ä¼˜åŒ–å’Œæ”¹è¿›ã€‚"
                3. "è¿™æ¯«æ— ç–‘é—®ï¼Œéšç€ç¡¬ä»¶å‘å±•ç›®å‰è®¡ç®—å¼•æ“å·²ç»ä»æ—©æœŸçš„io boundingè½¬å‘äº†cpu boundingï¼Œæˆ‘ä»¬çš„é›†ç¾¤ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œå› æ­¤å¦‚æœé‡æ„å¿…ç„¶è¦åŸºäºc++é‡å†™ï¼Œå¦å¤–ä¸€ä¸ªä¾‹è¯æ˜¯prestoä¹Ÿåœ¨åŸºäºc++åšnative query engineã€‚ç°åœ¨çš„è¶‹åŠ¿å°±æ˜¯åŸºäºc++æˆ–è€…rustæ„å»ºnativeçš„æ‰§è¡Œå¼•æ“ï¼Œæœªæ¥jvmçš„æ‰§è¡Œå¼•æ“å¯èƒ½ä¼šé€æ¸æ·¡å‡ºå†å²èˆå°å®Œæˆå…¶å†å²ä½¿å‘½ï¼Œåœ¨å¤§æ•°æ®æ—©æœŸå› ä¸ºå—é™äºç£ç›˜æˆ–è€…ç½‘ç»œï¼Œæ•´ä¸ªç³»ç»Ÿçš„ç“¶é¢ˆå¾€å¾€åœ¨IOï¼Œå› æ­¤jvmæ„å»ºæ˜¯åˆé€‚çš„ï¼Œå¯ä»¥æ›´å¿«çš„æ„å»ºå‡ºäº§å“æ¯”å¦‚hadoop spark prestoç­‰ã€‚

                ç›®å‰ç½‘ç»œæ™®éåœ¨20Gbpsç”šè‡³50G/100Gï¼ŒRDMAæŠ€æœ¯ï¼Œç£ç›˜ä¹Ÿä»æ—©æœŸçš„HDDå‘å±•åˆ°SSDï¼Œå‚²è…¾ç­‰å¸¦å®½æ›´å¤§ã€å»¶è¿Ÿæ›´ä½ï¼ŒåŠ ä¸Šè½¯ä»¶ä¸Šçš„å¼‚æ­¥é¢„å–ã€cacheã€å¹¶è¡Œè®¡ç®—ç­‰æŠ€æœ¯ï¼ŒIOç“¶é¢ˆå·²ç»åŸºæœ¬æ¶ˆé™¤ã€‚CPUé‡æ–°æˆä¸ºç“¶é¢ˆã€‚"
            4. Photon key points
                1. The Databricks Runtimeï¼ˆDBRï¼‰
                2. æ€»ä½“ä¸Šï¼Œphotonæ˜¯ç”¨c++å®ç°çš„ä¸€ä¸ªåˆ—å¼ã€æ‰¹å¤„ç†ä¹Ÿå°±æ˜¯vectorized query engineï¼Œä»¥shared libè¿å…¥åˆ°DBRï¼Œrun as part of single-threaded task in DBR within an executor's JVM process
                3. interpreted vectorization vs code-gen
                    1. è¿™é‡Œçš„ä¸»è¦é—®é¢˜æ˜¯è®¡ç®—æ¡†æ¶é‡‡ç”¨å‘é‡åŒ–è¿˜æ˜¯code genï¼Ÿå‰è€…ä»£è¡¨è®ºæ–‡æ˜¯monetdb/x100ï¼Œåè€…ä»£è¡¨è®ºæ–‡æ˜¯hyperã€‚å‰è€…çš„å®ç°ä»£è¡¨æ˜¯clickhouseï¼Œmonetdbï¼Œåè€…æ˜¯spark sqlï¼Œhyperï¼Œimpalaç­‰ã€‚
                4. partial roll out. å¦‚æœéƒ¨åˆ†ç®—å­è¿˜æ²¡æœ‰å®ç°ï¼Œé‚£ä¹ˆéœ€è¦èƒ½fallbackåˆ°è€çš„ä»£ç 
                5. "æ‰€ä»¥åœ¨photon spilling operatoræ¯”å¦‚hash joinï¼Œgroup byç­‰ï¼Œå¯¹äºè¾“å…¥æ•°æ®çš„å¤„ç†åˆ†ä¸º2ä¸ªé˜¶æ®µï¼Œç¬¬ä¸€é˜¶æ®µæ˜¯å†…å­˜çš„reservationï¼Œç¬¬äºŒé˜¶æ®µæ˜¯allocationé˜¶æ®µï¼Œè¿™æ ·å†ç¬¬äºŒé˜¶æ®µä¸ä¼šå‘ç”Ÿspillï¼Œè¿™æ ·å°±ä¿è¯äº†å½“å‰opçš„é«˜æ•ˆå¤„ç†ï¼Œphotonå›¢é˜Ÿä¹Ÿå¼ºè°ƒè¿™æ ·çš„ç­–ç•¥å¾ˆå…³é”®ï¼Œå› ä¸ºåœ¨contextä¸­æ•°æ®é‡ç»å¸¸å¾ˆå¤§å¦‚æœè¯´åœ¨å¤„ç†å½“å‰opç»å¸¸ä¼šå‘ç”Ÿspillçš„è¯ï¼Œæ•´ä¸ªæµç¨‹å°±åˆå¡ç£ç›˜IOäº†ï¼Œå¹¶ä¸èƒ½å‘æŒ¥å‡ºå‘é‡åŒ–æ‰§è¡Œå¼•æ“ä¼˜åŠ¿ã€‚"

19. PolarDB-IMCI: A Cloud-Native HTAP Database System at Alibaba    [2023, 3 refs, Alibaba, SIGMOD23]
    https://arxiv.org/abs/2305.08468
    1. Good. HTAP implemented with CALS commit-ahead log shipping, to dual-format RO nodes (row-wise vs columnar), and dedicate nodes to serve in-memory columnar index. user transparent of OLTP vs OLAP, by auto routing the queries.
       Replicate REDO log rather than binlog. è¯„ä¼°è¡¨æ˜ï¼Œé‡ç”¨REDOæ—¥å¿—çš„å¼€é”€æ˜æ˜¾ä½äºä½¿ç”¨Binlog. Two-Phase Conflict-Free Parallel Replay. Good innovation.
       TPC-H (100GB) ä¸Šå°†åˆ†ææŸ¥è¯¢é€Ÿåº¦æé«˜äº† 149 å€ï¼ŒOLTPå·¥ä½œè´Ÿè½½ä¸Šå¼•å…¥äº†ä½å»¶è¿Ÿå’Œå¾ˆå°çš„æ€§èƒ½æ‰°åŠ¨ï¼ˆ<5%ï¼‰ã€‚ Performance at ClickHouse level.
       PloarDB-IMCI claims to be the only database the achieved goals G#1 ~ G#5.
    2. Highlights
        1. See the article
        2. My questions
            1. PolarDB uses dedicated in-memory index served on dedicated node to support OLAP, but NOT columnar replica?
                1. "å¦‚å›¾4æ‰€ç¤ºï¼ŒPolarDB-IMCIä¸­çš„åˆ—ç´¢å¼•ä½œä¸ºç°æœ‰è¡Œå­˜å‚¨çš„è¡¥å……å­˜å‚¨ã€‚" Row Group data is still sent to Polar FS. It sees the columnar replica is just called in-memory column index here, and the in-memory index does have its on-disk components. maybe it requires all data to be loaded in-memory?
                2. It's called "index" probably due to RID locator, that is a link from keys to row ids.
                3. column index is rebuilt from row store. though column index have checkpoints.
                   "When adding a new RO node, PolarDB-IMCI first checks whether there is an available checkpoint of column indexes in PolarFS. If so, it loads the checkpoint and performs fast recovery; otherwise, it rebuilds column indexes from the row store."
            2. Single RW Nodes with Multiple RO Nodes. Is it really well to not scale out writers?
                1. partitioning should be supported
    n. related materials
        1. HTAP -- PolarDB-IMCI:A Cloud-Native HATP Database - Hugo
           https://zhuanlan.zhihu.com/p/639227492
        2. [SIGMOD2023] PolarDB-IMCI: A Cloud-Native HTAP Database System at Alibaba - è¥¿è¥¿å¼—æ–¯
           https://zhuanlan.zhihu.com/p/641678511
            1. Key points
                1. G#2: Advanced OLAP Performance
                    1. in-memory column index. 
                        1. Row Group é»˜è®¤æ¯ä¸ªè¡Œç»„ 64K è¡Œï¼Œ Pack metaè·Ÿè¸ªæœ€å°å€¼å’Œæœ€å¤§å€¼ä»¥åŠæ¯ä¸ª Pack çš„é‡‡æ ·ç›´æ–¹å›¾ã€‚
                        2. RID Locator. ç”±äº Packs ä¸­çš„æ•°æ®æŒ‰ç…§æ’å…¥é¡ºåºå­˜å‚¨ï¼ŒPolarDB-IMCI ä¾é Locatorå°†ä¸»é”®æ˜ å°„åˆ°åˆ—ç´¢å¼•ä¸­ç›¸åº”çš„ç‰©ç†ä½ç½®ã€‚åœ¨PolarDB-IMCIä¸­ï¼Œæ¯ä¸€è¡Œéƒ½æ ¹æ®å…¶æ’å…¥é¡ºåºåˆ†é…ä¸€ä¸ªé€’å¢ä¸”å”¯ä¸€çš„Row-ID (RID)ã€‚ç„¶åï¼ŒRID Locatorè®°å½•é”®å€¼å¯¹çš„æ˜ å°„ï¼ˆå³ <Primary Key, RID> ï¼‰
                        3. two-layer LSM tree.
                    2. ä¸ºäº†åŠ é€Ÿåˆ†ææŸ¥è¯¢ï¼ŒPolarDB-IMCIæ”¯æŒåœ¨ROèŠ‚ç‚¹çš„è¡Œå­˜å‚¨ä¸Šæ„å»ºin-memoryåˆ—ç´¢å¼•ã€‚åˆ—ç´¢å¼•æŒ‰æ’å…¥é¡ºåºå­˜å‚¨æ•°æ®å¹¶æ‰§è¡Œout-place å†™å…¥ä»¥å®ç°é«˜æ•ˆæ›´æ–°ã€‚æ’å…¥é¡ºåºæ˜¯æŒ‡åˆ—ç´¢å¼•ä¸­çš„ä¸€è¡Œå¯ä»¥é€šè¿‡å…¶RIDè€Œä¸æ˜¯å…¶ä¸»é”® (PK) å¿«é€Ÿå®šä½ã€‚ä¸ºäº†æ”¯æŒåŸºäºPKçš„ç‚¹æŸ¥æ‰¾ï¼ŒPolarDB-IMCIå®ç°äº†ç”¨äºPK-RIDæ˜ å°„çš„RID locatorï¼ˆå³ä¸¤å±‚LSMæ ‘ï¼‰ã€‚
                    3. PolarDBå¸¸è§„çš„åŸºäºè¡Œçš„æ‰§è¡Œå¼•æ“ç”¨äºæœåŠ¡OLTPæŸ¥è¯¢ï¼Œè€Œæ–°çš„åŸºäºåˆ—çš„æ‰¹å¤„ç†æ¨¡å¼æ‰§è¡Œå¼•æ“åˆ™ç”¨äºé«˜æ•ˆè¿è¡Œåˆ†ææŸ¥è¯¢ã€‚æ‰¹å¤„ç†æ¨¡å¼æ‰§è¡Œå¼•æ“åˆ©ç”¨åˆ—å¼æ•°æ®åº“å¤„ç†åˆ†ææŸ¥è¯¢çš„æŠ€æœ¯ï¼ŒåŒ…æ‹¬pipelineæ‰§è¡Œæ¨¡å‹ã€å¹¶è¡Œç®—å­å’Œå‘é‡åŒ–è¡¨è¾¾å¼è¯„ä¼°æ¡†æ¶ã€‚
                    4. Handle Large Transactions
                        1. å¦‚æœä¸€ä¸ªäº‹åŠ¡åŒ…å«è¿‡å¤šçš„æ“ä½œï¼Œåˆ™å…¶äº‹åŠ¡ç¼“å†²å•å…ƒå¯èƒ½ä¼šæ¶ˆè€—å·¨å¤§çš„å†…å­˜ã€‚ä¸ºäº†é¿å…è¿‡å¤šçš„å†…å­˜æ¶ˆè€—ï¼ŒPolarDB-IMCIå¯¹å¤§äº‹åŠ¡è¿›è¡Œäº†pre-commits ï¼šå½“äº‹åŠ¡ç¼“å†²å•å…ƒä¸­çš„ DML è¯­å¥æ•°é‡è¾¾åˆ°ç»™å®šé˜ˆå€¼æ—¶ï¼Œå°±ä¼špre-committedã€‚
                    5. Plan Generation
                        1. PolarDB-IMCIä¸æ˜¯è‡ªä¸Šè€Œä¸‹æ„å»ºé¢å‘åˆ—çš„æ‰§è¡Œè®¡åˆ’ï¼Œè€Œæ˜¯å°†å…¶ä»é¢å‘è¡Œçš„æ‰§è¡Œè®¡åˆ’è½¬å˜ä¸ºé¢å‘åˆ—çš„æ‰§è¡Œè®¡åˆ’ã€‚PolarDB-IMCIä½¿ç”¨DPhypä½œä¸ºjoin orderç®—æ³•ï¼Œé€šè¿‡éšæœºé‡‡æ ·çš„æ–¹å¼æœé›†ç»Ÿè®¡ä¿¡æ¯ã€‚
                            1. Interesting
                        2. PolarDB-IMCIä½¿ç”¨DPhypä½œä¸ºjoin orderç®—æ³•ï¼Œé€šè¿‡éšæœºé‡‡æ ·çš„æ–¹å¼æœé›†ç»Ÿè®¡ä¿¡æ¯ã€‚
                2. G#3: èµ„æºéš”ç¦»
                    1. ç´¢å¼•é©»ç•™åœ¨å•ç‹¬çš„ROèŠ‚ç‚¹ä¸Šï¼Œå¹¶é‡‡ç”¨å…±äº«å­˜å‚¨æ¶æ„
                3. G#4: é«˜æ•°æ®æ–°é²œåº¦çš„å®ç°
                    1. é‡ç”¨REDOæ—¥å¿—æ¥åœ¨å¼‚æ„å¼•æ“é—´åšåŒæ­¥
                        1. è¯„ä¼°è¡¨æ˜ï¼Œé‡ç”¨REDOæ—¥å¿—çš„å¼€é”€æ˜æ˜¾ä½äºä½¿ç”¨Binlog. ä½¿ç”¨ Binlog çš„å¼€é”€æ˜æ˜¾æ›´é«˜ï¼Œå› ä¸º Binlog ä¼šäº§ç”Ÿé¢å¤–çš„ fsync å’Œæ›´å¤šçš„æ—¥å¿— IOã€‚
                        2. Data freshness is guaranteed because RO èŠ‚ç‚¹çš„replayååé‡è¿œé«˜äº RW çš„ OLTP ååé‡ï¼ˆå›¾ 13ï¼‰
                    2. commit-ahead log shipping (CALS)å’Œ2-Phase conflict-free log replay (2P-COFFER)å¢å¼ºäº†æ›´æ–°ä¼ æ’­æ¡†æ¶ã€‚
                        1. CALS åœ¨æäº¤ä¹‹å‰ä¼ é€äº‹åŠ¡æ—¥å¿—ï¼›2P-COFFERé«˜æ•ˆè§£æREDOæ—¥å¿—å¹¶å°†å…¶åº”ç”¨åˆ°ROèŠ‚ç‚¹ã€‚
                        2. Interesting.
                        3. Two-Phase Conflict-Free Parallel Replay
                            1. PolarDB-IMCI ä¸ä¼šä¸ºæ›´æ–°ä¼ æ’­ç”Ÿæˆé¢å¤–çš„é€»è¾‘æ—¥å¿—ï¼Œè€Œæ˜¯å¤ç”¨ REDO æ—¥å¿—ã€‚ 
                                1. REDOæ—¥å¿—åªè®°å½•è¡Œå­˜å‚¨ä¸­ç‰©ç†é¡µçš„å˜åŒ–ï¼Œç¼ºä¹æ•°æ®åº“çº§æˆ–è¡¨çº§ä¿¡æ¯
                                2. ç”±è¡Œå­˜å‚¨æœ¬èº«è€Œä¸æ˜¯ç”¨æˆ·DMLå¼•èµ·çš„é¡µé¢æ›´æ”¹ä¹ŸåŒ…å«åœ¨REDOæ—¥å¿—ä¸­ï¼Œä¾‹å¦‚B+æ ‘æ‹†åˆ†/åˆå¹¶å’Œé¡µé¢åˆå¹¶ã€‚åˆ—ç´¢å¼•ä¸èƒ½åº”ç”¨è¿™äº›æ—¥å¿—ï¼Œå¦åˆ™å¯èƒ½ä¼šå‡ºç°ä¸ä¸€è‡´çš„æƒ…å†µã€‚
                                3. REDOæ—¥å¿—åªåŒ…å«å·®å¼‚ï¼Œä¸åŒ…å«å®Œæ•´æ›´æ–°
                            2. å¦‚å›¾6æ‰€ç¤ºï¼ŒPolarDB-IMCIé€šè¿‡ä¸¤ä¸ªé‡æ”¾é˜¶æ®µè§£å†³äº†è¿™äº›æŒ‘æˆ˜ã€‚
                                1. Phase#1 æ˜¯å°† REDO æ—¥å¿—replayåˆ° RO ä¸­è¡Œå­˜å‚¨çš„in-memoryå‰¯æœ¬ã€‚åœ¨è¿™ä¸ªé˜¶æ®µï¼ŒPolarDB-IMCIæ•è·å®Œæ•´çš„ä¿¡æ¯ï¼Œå°†REDOæ—¥å¿—è§£æä¸ºé€»è¾‘DMLè¯­å¥ã€‚
                                2. Phase#2 æ˜¯å°† DML è¯­å¥replayåˆ°åˆ—ç´¢å¼•ã€‚
                            2. replayçš„æ€§èƒ½å¯¹äºæˆ‘ä»¬çš„ç³»ç»Ÿè‡³å…³é‡è¦ï¼Œä¸ºäº†å®ç°é«˜æ€§èƒ½ï¼Œç›¸å…³æ–‡çŒ®ä¸­æå‡ºäº†å‡ ç§å¹¶è¡Œé‡æ”¾æœºåˆ¶ã€‚è¿™äº›å·¥ä½œè¦ä¹ˆåœ¨å†²çªå¤„ç†è¾…åŠ©å·¥å…·ï¼ˆä¾‹å¦‚é”æˆ–ä¾èµ–å›¾ï¼‰æˆ–ä¹è§‚æ§åˆ¶çš„å¸®åŠ©ä¸‹ï¼Œä»¥ä¼šè¯ç²’åº¦æˆ–äº‹åŠ¡ç²’åº¦è¿›è¡Œå¹¶è¡Œé‡æ’­ã€‚ä¸è¿™äº›ä½œå“ä¸åŒçš„æ˜¯ï¼ŒPolarDB-IMCIæå‡ºäº†ä¸€ç§æ–°çš„é‡æ”¾æ–¹æ³•2P-COFFERï¼Œä½¿å¹¶è¡Œé‡æ”¾çš„ä¸¤ä¸ªé˜¶æ®µéƒ½æ— å†²çªã€‚åœ¨2P-COFFERä¸­ï¼ŒPhase#1æ˜¯é¡µç²’åº¦çš„ï¼Œè€ŒPhase#2æ˜¯è¡Œç²’åº¦çš„ï¼Œä»¥å®ç°ä¸åŒé¡µ/è¡Œçš„å¹¶å‘ä¿®æ”¹ã€‚ä¿®æ”¹åŒä¸€é¡µ/è¡Œä½†å±äºä¸åŒäº‹åŠ¡çš„æ—¥å¿—entryè¢«è§†ä¸ºç›¸å…³æ—¥å¿—ï¼Œåº”æŒ‰é¡ºåºreplayã€‚ä½¿ç”¨ 2P-COFFERï¼ŒRO èŠ‚ç‚¹çš„replayååé‡è¿œé«˜äº RW çš„ OLTP ååé‡ï¼ˆå›¾ 13ï¼‰ã€‚
                                1. Good.
                4. G#1: Transparent Query Execution. 
                    1. ä¸ºäº†åœ¨å•ä¸ªæ•°æ®åº“ä¸­æœåŠ¡æ··åˆå·¥ä½œè´Ÿè½½ï¼Œä¸åº”è¯¥è¦æ±‚æ•°æ®åº“ç”¨æˆ·äº†è§£æ•°æ®åº“çš„å·¥ä½œé€»è¾‘ï¼Œä¹Ÿä¸åº”è¯¥æ‰‹åŠ¨è¯†åˆ«æŸ¥è¯¢ç±»å‹
                    2. æ–°çš„æŸ¥è¯¢è·¯ç”±æœºåˆ¶ï¼Œå¯ä»¥é€æ˜åœ°è°ƒåº¦æŸ¥è¯¢
                        1. "å¦ä¸€ç§ç±»å‹çš„ HTAP æ•°æ®åº“åˆ©ç”¨replicationæŠ€æœ¯æ¥ç»´æŠ¤å¤šä¸ªå®ä¾‹ã€‚å› æ­¤ï¼ŒTPå’ŒAPæŸ¥è¯¢å¯ä»¥è·¯ç”±åˆ°ä¸åŒçš„å®ä¾‹ï¼Œä»¥å®ç°é«˜æ•ˆçš„æ€§èƒ½éš”ç¦»ã€‚"
                        2. PolarDB - æŸ¥è¯¢å¯ä»¥é€šè¿‡åŸºäºä»£ä»·çš„è·¯ç”±åè®®åœ¨ä¸åŒçš„èŠ‚ç‚¹å’Œä¸åŒçš„æ‰§è¡Œå¼•æ“ä¸Šæ‰§è¡Œã€‚routing processå¯¹åº”ç”¨ç¨‹åºå’Œç”¨æˆ·å®Œå…¨é€æ˜ï¼Œå¹¶å…·æœ‰ä¸¤çº§ç­–ç•¥ï¼šèŠ‚ç‚¹é—´è·¯ç”±å’ŒèŠ‚ç‚¹å†…è·¯ç”±ã€‚èŠ‚ç‚¹é—´è·¯ç”±é€šè¿‡proxyå±‚å®ç°è¯»/å†™æµæ‹†åˆ†ï¼ˆå¸¦è´Ÿè½½å‡è¡¡ï¼‰ï¼Œè€ŒèŠ‚ç‚¹å†…è·¯ç”±åˆ™é€šè¿‡ä¼˜åŒ–å™¨æä¾›æ•°æ®access pathå’Œæ‰§è¡Œå¼•æ“ï¼ˆåŸºäºè¡Œæˆ–åŸºäºåˆ—ï¼‰çš„åŠ¨æ€é€‰æ‹©ã€‚
                5. G#5: Excellent Resource Elasticity
                    1. åˆ—å¼ç´¢å¼•çš„checkpointæœºåˆ¶è¢«æ— ç¼å†…ç½®åˆ°PolarDBåŸæœ‰çš„å­˜å‚¨å¼•æ“ä¸­ã€‚å› æ­¤ï¼Œå¯ä»¥é€šè¿‡ä½¿ç”¨å…±äº«å­˜å‚¨ä¸Šçš„checkpointå¿«é€Ÿæ‹‰èµ· RO èŠ‚ç‚¹æ¥å®ç°å¿«é€Ÿæ¨ªå‘æ‰©å±•èƒ½åŠ›
            2. Background
                1. TPä¸APä¹‹é—´æ•°æ®åŒæ­¥çš„åšæ³•ä¸»è¦æœ‰ï¼š
                    1. SAP HANA æœ€è¿‘çš„ä¸€é¡¹å·¥ä½œæå‡ºäº†ATRï¼ˆAsynchronous Table Replicationï¼‰ï¼Œç”¨äºä¸»å®ä¾‹å’Œå‰¯æœ¬ä¹‹é—´çš„æ•°æ®åŒæ­¥
                    2. Google F1 Lightning ä½¿ç”¨CDCï¼Œé€šè¿‡ BigTable shufflingæ•°æ®
                    3. TiDBä½¿ç”¨ Raftè¿æ¥è¡Œå­˜å‚¨å¼•æ“ï¼ˆTiKVï¼‰å’Œåˆ—å­˜å‚¨å¼•æ“ï¼ˆTiFlashï¼‰
                    4. IBM DB2 Analytics Accelerator (IDAA)é€šè¿‡é›†æˆåŒæ­¥ç»´æŠ¤åŸºäºè¡Œçš„è¡¨æ•°æ®çš„å‰¯æœ¬ï¼Œä»¥æ”¯æŒå¢é‡æ›´æ–°
                    5. æ–°ç‰ˆæœ¬çš„ Oracle Dualæ”¯æŒå°†åªè¯»å·¥ä½œè´Ÿè½½offloadingåˆ°åŒæ„å®ä¾‹ï¼Œå¹¶é€šè¿‡ REDO æ—¥å¿—åŒæ­¥æ•°æ®ã€‚
                    6. ByteHTAPä½¿ç”¨disaggregatedå­˜å‚¨ï¼Œé€šè¿‡Binlog åŒæ­¥å¼‚æ„å¼•æ“ï¼ˆç”¨äº OLTP çš„ ByteNDB å’Œç”¨äº OLAP çš„ Apache Flinkï¼‰
                    7. Wildfireæ˜¯ä¸€ä¸ªä¸ Spark å…¼å®¹çš„æ•°æ®åº“ï¼Œè¿˜åˆ©ç”¨disaggregatedå­˜å‚¨è¿›è¡Œæ•°æ®åŒæ­¥ã€‚ 
                    8. "ä¸è¿™äº›å·¥ä½œä¸åŒçš„æ˜¯ï¼ŒPolarDB-IMCIç›´æ¥å¤ç”¨REDOæ—¥å¿—è¿›è¡Œå¼‚æ„æ•°æ®å¤åˆ¶ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒPolarDB-IMCIæ˜¯ç¬¬ä¸€ä¸ªä½¿ç”¨ç‰©ç†æ—¥å¿—æ¥é«˜æ•ˆåŒæ­¥å¼‚æ„å­˜å‚¨çš„å·¥ä¸šæ•°æ®åº“ã€‚"

20. ROLEX: A Scalable RDMA-oriented Learned Key-Value Store for Disaggregated Memory Systems    [2023, 7 refs, FAST23, Best paper award]
    https://www.usenix.org/conference/fast23/presentation/li-pengfei
    https://github.com/iotlpf/ROLEX
    1. Very good. PLR learned index, 2~4 orders of magnitudes smaller than B+tree, that can full index cached at client-side (compute node).
       Maintains (partial) sorting, allows asynchronized retrain withotu interruption, supports high write ingestion speed with SLT.
       Outperforms contemporary indexes either B+tree based or learned index based, as much as ~2.2x in a r/w mixed workload.
       The inode index structure in Distributed File System may find use.
        1. Following Orion/Octopus, to XStore, FORD, to ROLEX, Citron, we can look forward the entire database can be built with one-sided RDMA on mem/PMEM nodes in a disaggregated way. The index is large and distributed to nodes at all clusters.
    2. Highlights
        1. Background
            1. Disaggregated memory
                1. In-memory KV store that supports range query and point query. Index is distributed across multipe nodes.
                   If using B+tree, a lookup may need multiple RDMA rounds to each node. Think about Distributed Filesystem inodes.
                2. Memory nodes and compute nodes. Memory nodes have limited computation resource, but with FPGA or ARM chips.
                3. One-sided RDMA. Use RDMA FAA and CAS to support one-sided atomic operations. However, the max atomic unit is 8-byte.
                   The 8-byte poses limitation to the entry size and index size that need to be atomically operated.
                   But we can implement 1-bit lock to allow larger scope synchronization.
            2. Learned index
                1. PLR - Piece-wise Linear regression model. It first requests keys to be sorted. Then storage postition can be predicted with a linear model + accepted error range Îµ. Pattern can shift, then the total key space is cut into segments, where each piece uses a line linear.
                2. Compared to B+tree, Learned indexes can achieve 2~4 orders of magnitude memory saving.
                    1. While B+tree usually caches top nodes in compute node, Learned index allows caching all index into. Thus, a lookup can be done with one round of one-sided RDMA.
                        1. Good, this is the paradigm shift.
        2. ROLEX
            1. index structure
                1. A piece in PLR maps to a "Leaf", i.e., Leaf Region, as a consecutive range of keys, sorted.
                   Data movement is restricted with in a Leaf. A Leaf allows Î´ width of keys. PLR's resolution is Leaf.
                   Î´ is the extended error acceptance range of PLR's piece. In this way, updates won't make a stale PLR model miss to find data.

                2. Keep inserting keys into the Leaf, it may overflow, then the paper introduced Synonym-leaf.
                   It's extra regions linked to Leaf to absorb overflow data. So that a stale PLR model can still serve.
                3. Upper models: A PLR model can be too finer grain, then an upper level PLR can be trained. Layer and layer up.
                    1. like PGM-index [14]
                    2. All are fully cached at compute node
                4. Leaf Table (LT) and Synonym Leaf Table (SLT) to track Leafs
                    1. Retrain won't change Leaf, nor data movement or resorting. The PLR model and LT/SLT are separated.
            2. Retrain
                1. Generate new LT/SLT in the shadow mode, and then switch
                    1. Some concurrency guarantees need to check both old and new LT/SLT
                2. Retrain is fast, only ~300Î¼s. Asynchronized and non-interrupting to concurrent writes
                    1. concurrent writes are offloaded to new Synonym Leafs, pending the next retrain
                3. Retrain is put to the memory node rather than compute node.
                    1. The argument is memory node's computation is limited, but still enough.
                       And this approach doesn't need to transfer huge data with compute node.
                4. Fine-grained model retraining. CirQ tracks the models pending training.
            3. Concurrency
                1. RDMA FAA and RDMA CAS on 8-byte entries.
                2. 1-bit lock field via RDMA CAS. Lock is at individual leaf level, rather than full LT
            4. Optimizations
                1. PLR's position prediction is transferred to the leaf prediction.
                2. Multiple writes into the same Leaf or Synonym Leafs can be batched to share the lock.
                3. ROLEX doesn't need to resort or move any data for retraining.
                4. RDMA Doorbell batching.
            5. Others
                1. By the narratives from the paper. ROLEX seems started from adapting XStore to disaggregated memory system, XStore-D.
                   Then it hits problem that XSTore-D cannot efficiently handle heavy modifications writes.
                    1. XStore uses a hybrid index, B+tree a memory nodes, and Learned Index cached at compute node.
                       The previous paper targets static workload with no or few modification, or use a monolithic compute+memory node.
                    2. ROLEX doesn't use B+tree at all. Fully learned index. Retrain is made fast and non-interruptive, and don't require RDMA communication between compute and memory nodes.
        3. My questions
            1. The paper keeps saying RDMA bandwidth has limitation and should avoid RDMA communication. But then why heading to the disaggregated memory architecture?
                1. Maybe XStore's monolithic architecture is the right way?
            2. PLR learned index requires keys to be maintained in sorted order. From this paper, maybe sort is only required within individual Leaf, but not cross Leaf.
               How much cost is needed for maintaining such sorting? Maybe this is why range query is a must-have brought into compare.
               Retrain then should need to use merge-sort across Leafs. Then that's why O(N) is mentioned in retrain complexity.
                1. Also, I didn't see a benchmark compare dedicated for range queries.
            3. PLR's position prediction is transferred to the leaf prediction. Is there extra cost to scan intra Leaf?
            4. After memory node done retrain, how does compute node's cached index gets updated and maintain consistency?
                1. Maybe old index is still kept, and compute node gets aware of the new index after the next read.
            5. The evaluation cluster only has 3 compute node and 3 memory nodes. How does it evaluate scalability?
                1. And, when there is a larger cluster, does it still work to cache full Leaned index in compute node?
            6. Figure 9 shows ROLEX is doing well at writes that outperforms others, but not as well in reads. Is this implicating Learned Index still has some overhead in reads? The improvements in writes should be attributed to Learned Index or something else? 

    n. related materials
        1. Correct, Fast Remote Persistence    [2019, 6 refs]
           https://arxiv.org/pdf/1909.02092.pdf
            1. RDMA FAA, CAS, 8-byte unit
                1. RDMA one-sided ATOMIC operation
            2. DDIO [12] is the feature on Intel processors that enables delivery of incoming RDMA data from the responder's RNIC directly into the L3 cache
        2. Design Guidelines for High Performance RDMA Systems    [2016, 386 refs]
           https://anujkalia.com/doc/atc16/rdma_bench_atc.pdf
            1. Doorbell batching

        3. FAST'23 ROLEX: A Scalable RDMA-oriented Learned Key-Value Store for Disaggregated Memory Systems - DielnADream
           https://zhuanlan.zhihu.com/p/613951397
        
        4. æ·±å…¥è§£è¯»ROLEXåˆ†ç¦»å¼å†…å­˜ç³»ç»Ÿï¼šFAST'23 æœ€ä½³è®ºæ–‡æ­ç§˜ - å­˜å‚¨å‰æ²¿æŠ€æœ¯è¯„è®º
           https://zhuanlan.zhihu.com/p/665173526
            1. "è™½ç„¶ROLEXå…¨ç¯‡æœªæåŠCXLï¼Œä½†æ˜¯äº†è§£CXLæ¦‚å¿µçš„ç ”ç©¶äººå‘˜åº”è¯¥èƒ½æ„è¯†åˆ°åˆ†ç¦»å¼å†…å­˜æŠ€æœ¯ä¸CXLæŠ€æœ¯è¶‹åŠ¿çš„å…³è”ã€‚"

        5. XStore: Fast RDMA-based Ordered Key-Value Store using Remote Learned Cache    [2020, 56 refs, OSDI 20]
           https://www.usenix.org/conference/osdi20/presentation/wei
            0. ROLEX is motivated by trying to apply XStore to disaggregated memory with async retrain.
            1. Good. The idea of client side to cache a learned index.
            2. Highlights
                1. Problems
                    1. Client needs multiple one-sided RDMA round trips are needed to traversal a big B+tree index
                2. XStore solution
                    1. Cache learned index at Client. Learned index takes 2~4 orders or magnitude less memory. 1 RTT is needed.
                        1. second problem: learned index assumes a sorted array. How to handle dynamic workload
                            1. solution: Translation table (TT) that makes keys logically sorted. Though B+tree insertion won't physically maintain keys sorted.
                    2. server centric update, since one-sided RDMA semantics are too simple
                        1. In compare ROLEX achieved compute node side index update
                    3. Model retraining at server side in background
                        1. two-layer RMI to organize the models. Fine-grained model retraining.
                        2. Stale model still can correctly find most keys, given logical address in TT didn't change
                        3. XMODEL uses a linear multi-variate regression model at level 0 (top-model) and simple linear regression models at level 1 (sub-model)
                        4. Model & TT retraining happens at Server. Client retrieves models and TT on-demand
                3. My questions
                    1. Can TT be integrated into the learned index model, so that the model doesn't require sorted keys?

        6. FORD: Fast One-sided RDMA-based Distributed Transactions for Disaggregated Persistent Memory    [2022, 29 refs, FAST22]
           https://www.usenix.org/conference/fast22/presentation/zhang-ming
            0. Same authors Yu Hua, Pengfei Zuo, Same school with ROLEX
            1. One-sided RDMA for distributed transaction on remote PMEM pool, with optimizations. Locking is needed.
            2. Highlights
                1. Problems to solve
                    1. Disaggregated memory, PMEM. Transaction needs to reduce one-sided RDMA round trips.
                        1. Too many RTTs: Execution, locking, validation, commit backup, commit primary each * replica count.
                    2. PEM pool has weak computation resources. Compute nodes have small RDMA caches.
                    3. Write consistency to the remote PMEM
                2. FORD solutions
                    1. Hitchhiked locking
                        1. Locking is attached to read requests, to save RTTs.
                        2. RDMA doorbell mechansim to batch the RDMA CAS followed by RDMA read in one request
                    2. Coalescent commit
                        1. In-place update. Parallel undo logging in execution phase, wait logging asynchronously.
                        2. Prevent reading partial updates, but release locks after commit.
                    3. Backup-enabled read
                        1. Allow backups to serve read-only (RO) requests. Correctness by version checks.
                    4. Selective remote flush
                        1. Only issue remote flushes to backups after the final write. RDMA supports such one-sided flash operation
                            1. My questions
                                1. think about Group Commit or Group Flush
                        2. "As RDMA FLUSH is currently unavailable in programming due to the needs of modifying RNIC and PCIe [48], we leverage one-sided RDMA READ-after-WRITE to flush the data in RNIC to memory like [27, 31]."

        7. Citron: Distributed Range Lock Management with One-sided RDMA    [2023, 1 refs, FAST23]
           https://www.usenix.org/conference/fast23/presentation/gao
            0. Quite a few one-sided RDMA papers from Huazhong University of Science and Technology, Shanghai Jiao Tong University, Tsinghua University, this year
            1. Lock management with Segment tree. Access and managing lock with one-sided RDMA. RDMA Ext-CAS, Ext-FAA.
               Evaluated with 3 clients + 1 server. Citron vs one-sided RDMA: Citron is better when more clients.
            2. Highlights
                1. Problems to solve - DRLM (Distributed Range Lock Management)
                    1. CPU solutions use too much CPU
                        1. E.g., Marple tree in Linux
                    2. Oversized lock
                        1. Throughput-optimal vs Latency-optimal
                            1. Precise mapping is well for throughput, but can lock O(logN) nodes in worst case
                               Lock only one node is fast, but can generate false conflicts
                2. Citron solution
                    1. Segment tree
                        1. Throughput-optimal vs Latency-optimal
                            1. Use k=2 lock 2 nodes. which reduces ~96% false conflicts than k=1
                        2. Selecting nodes - knapsack algorithm
                            1. Should I split here?
                                1. Weight: # children nodes to lock - 1
                                   Value: Preciseness improvement
                        3. Node X conflicts only with ancestors and descendants
                            1. Lock the node X -> notify ancestors/descendants -> detect
                                1. Citron simplifies lock conflict resolution into the communication between ancestor and descendant nodes on the tree
                        4. Others
                            1. fan-out degree is four
                            2. leaf nodes represent ranges of size 64, not the 1 in the orthodox definition
                            3. Starvation avoidance
                            4. Notify ancestors, wait for descendants: meet-in-the-middle (MITM)
                            5. Scale up/down the lock tree
                    2. RDMA extended atomics
                        1. Ext-CAS, Ext-FAA
                        2. occupied flag, head, rear, d_head, d_rear
                        3. Leaf node: bitmap
                3. My questions
                    1. But the CPU consumption is moved to Client side?

21. CJFS: Concurrent Journaling for Better Scalability    [2023, 0 refs, FAST23]
    https://www.usenix.org/conference/fast23/presentation/oh
    1. Interesting. How to commit filesystem journal transactions in parallel, even they are on the same CPU core.
       The solution is, dual-thread (upper half vs bottom half), multi-versioning snapshot (shadow paging), try_lock (opportunistic coalescing), and group commit/flush.
       The original motivation should be why BarrierFS performs even worse than EXT4 on varmail_shared workload. And also borrowed ideas from XFS.
    2. Highlights
        1. Problems to solve
            1. Commit transactions in parallel, even they are to the same region or on the same CPU core
                1. See section 3.3 analysis, and section 5 discussion. They are well summaries.
        2. CJFS
            1. Dual Thread Journaling
                1. A transaction is separated into two parts
                    1. host side: Lock up, Prepare DMA
                       storage side: DMA transfer, flush
                2. Previously, transactions are serial. They cannot overlap.
                   Now, host-side and storage-side can overlap.
                    1. Pipelined commit with order-preserving block device
            2. Multi-version Shadow Paging
                1. Previously, two transactions are serial, because they have overlapping write set.
                   Now, in the write set, non-overlapping keys are write in parallel. overlapping keys can write one by one with version tagged.
                   At transaction level, their writing are overlapping
            3. Opportunistic Coalescing
                1. Previously, when Tx1 is DMA transfer and flushing, Tx2 has to wait.
                   Now, Tx2 can coalescing itself into Tx1's DMA & flushing.
                2. try_lock. check conflict, then preempt or avoid get into the LOCKED state.
            4. and Compound Flush
                1. Now, Tx's host side and storage side each have to be serial, though the two can overlap
                   Next, Host side and DMA transfer each is serial, the two can overlap.
                   The Flush is moved to the last, and merged all Tx in group into one Flush.
        3. Evaluation
            1. CJFS vs BarrierFS vs EXT4
            2. Usecase: Varmail 40 threads. high queue depth as transactions are transferred in parallel
        4. Others
            1. Table 1: Categories of existing scalable filesystems
                1. Good summary.
            2. CJFS transaction lock-up is preemptive. It checks if there is conflict, transaction can be unlocked.
        5. My questions
            1. Log can be striped. App needs a sequence/timestamp/LSN, but it can be pure logical.
                Transactions non-conflicting don't need to wait for each other. They can write log in parallel. Their ordering can be logical.
                Unlike database transaction, filesystem metadata journaling transactions don't even need the explicit read/commit timestamp. Then inode locking is sufficient, no need for sequencer service.

            2. Concurrent writing can be allowed by multi-version. It maps to shadow paging in this paper.
                Tx1 read and Tx2 read can go parallel, rather than wait on a locked page. It works like reading snapshots. It maps to Opportunistic Transaction Coalescing in this paper.
                EXT4 filesystem doesn't require to ensure durability when transaction committed. So after Tx1 committed its writes to persistence shuttle bus, Tx2 can immediately start, even Tx1's persistence is still on-going. It maps to Dual Thread Journaling in this paper.
                Writes to disk can be batched, i.e., group commit or group write, to reduce the number of fsync() calls. It maps to Compound Flush in this paper.

            3. So, the key take away from this paper is. Instead of building a single serial log, we can allow non-conflicting transactions to read/write in parallel. MVCC helps allow concurrent Txs.
                Underlyingly, logs can also be partitioned to improve throughput. Like a few single serial logs are grouped together to become one high-throughput partitioned log.
                Besides, filesystem can build per-core or per-inode journaling. and In each core, further applies the optimization in this paper.
                There is another multi-threaded approach, that it cuts journal commit into multiple stages, and organize them into a multi-staged pipeline.

            4. This paper's prior work is BarrierFS. Reading section 3.3, the initial motivation should be how BarrierFS performs worse than EXT4 on varmail-shared. BarrierFS commits transactions in parallel, but they still become serial at flush. BarrierFS transactions commonly conflict on inode block and bitmap, while shadow paging is not effective. BarrierFS puts transaction at LOCKED state too early, and should have leveraged coalescing. Section 5 Discussion has more compares of CJFS vs BarrierFS. Another thing is this paper CJFS seems have borrowed quite a few from XFS. 

        n. related materials
            1. BarrierFS: Barrier-Enabled IO Stack for Flash Storage    [2018, 62 refs, FAST18 best paper award]
               https://www.usenix.org/conference/fast18/presentation/won
                0. Same author Youjip Won, Joontaek Oh.

            2. CORFU: A Shared Log Design for Flash Clusters
               https://www.cs.yale.edu/homes/mahesh/papers/corfumain-final.pdf
                1. compared to the parent paper, we can also shard the logs.
                   The serial log is striped to flash devices. stripe mapping is static.
                   A sequencer is introduced to optionally reduce the contention in acquiring the log tail.

            3. ScaleFS: Scaling a file system to many cores using an operation log    [2017, 66 refs]
               https://people.csail.mit.edu/nickolai/papers/bhat-scalefs.pdf
                0. As mentioned in the parent paper, per-core journaling
                1. sv6 [12] in-memory FS + xv6 [12] on-disk FS. In-memory per-core logs -> merge & order by timestamp -> fsync to disk.
                   commutative filesystem operations should run conflict free
                2. Highlights
                    1. Decouple the in-memory filesystem from the on-disk filesystem
                        1. Like CJFS dual thread. And Linux FS usually doesn't write commit durability unless fsync().
                        2. Both NOVA [42] and ScaleFS use per-core logs, but ScaleFS separates in-memory filesystem
                    2. In-memory filesystem is built with OpLog [5]
                        1. OpLog consists of
                            1) per-core logs
                            2) when fsync is called, ScaleFS merges per-core logs with timestamp and apply them to disk
                            3) ScaleFS is designed that no interaction is necessary between two cores 
                        2. mnode in memory vs inode on disk
                    3. Scalable Commutativity Rule [10] - The Scalable Commutativity Rule: Designing Scalable Software for Multicore Processors
                        1. ScaleFS uses sv6 [10] to build in-memory filesystem. sv[6] has special parallelism design that makes commutative operations conflict free (see Figure 8)
                        2. Disk filesystem is built with xv6 [12]. So ScaleFS is sv6 + xv6?
                    4. Handling non-local operations - rename
                        1. Operations take lock on inode
                           Use CPU clock RDTSCP to timestamp log operations
                           ALl directory modifications in in-memory FS must be linearizable
                           fsync orders the operations by their timestamp, in the same order that they were applied to MemFS. 
                n. Related materials
                    1. Scaling a file system to many cores using an operation log
                       https://nan01ab.github.io/2018/03/ScaleFS.html

                    2. The Scalable Commutativity Rule: Designing Scalable Software for Multicore Processors    [2015, 247 refs]
                       https://web.eecs.umich.edu/~ryanph/eecs582/fall23/readings/commutativity.pdf
                       https://dl.acm.org/doi/pdf/10.1145/3068914
                        1. scalable commutativity rule - whenever interface operations commute, they can be implemented in a way that scales, i.e., conflict-free.
                            1. Good, this is actually simple and intuitive. Even broader than the concept "symmetric multi-replica" å¯¹ç§°å¤šå‰¯æœ¬
```