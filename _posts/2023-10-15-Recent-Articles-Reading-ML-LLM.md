---
layout: post
title: "Recent Articles Reading: Machine Learning and LLM"
tagline : "Recent Articles Reading: Machine Learning and LLM"
description: "Recent Articles Reading: Machine Learning and LLM"
category: "Paper Reading"
tags: [ML, paper, LLM, AI]
---
{% include JB/setup %}

Large Language Model / LLM. Training in distributed framework and parallel models. GPT-4V.

````
8. ChatGPT ä¸ºä»€ä¹ˆä¸ç”¨ Reward-Model çš„æ•°æ®ç›´æ¥ fine-tuneï¼Œè€Œç”¨ RLï¼Ÿ - Andy Yang
   https://www.zhihu.com/question/596230048/answer/3002469682
    1. å¤šæ ·æ€§è§’åº¦ï¼šä¸ä»…ä»…ç”ŸæˆSLæŒ‡å®šçš„â€œæ­£ç¡®ç­”æ¡ˆâ€, "rather than trying to replicate the human responses directly"
       è´Ÿåé¦ˆè§’åº¦
       è‡ªæˆ‘çŸ¥è¯†æ„ŸçŸ¥è§’åº¦ï¼šä¸è¦ç¼–é€ 
    n. related materials
        1. Reinforcement Learning for Language Models
           https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81
            1. The core argument
                1. There are (at least) three modes of interaction with a language model
                    1. (a) text-grounded: we provide the model with a text and an instruction ("summarize this text", "based on this text, what is the population of Israel", "what are the chemical names mentioned in this text", "translate this text to spanish", etc), and expect the answer to be fully grounded in the provided text.
                    2. (b) knowledge-seeking: we provide the model with a question or instruction, and expect a (truthful) answer based on the model's internal knowledge ("What are common causes of flu").
                    3. (c) creative: we provide the model with a question or instruction, and expect some creative output. ("Write a story about...")
                2. The argument for RL is based on interaction type (b): knowledge-seeking queries in which we expect a truthful (or confident) answer, and the ability of the model to say "I don't know" or refuse to answer in situations in which it is uncertain.
                3. We cannot use pure supervised learning to push the model for producing truthful answers, and we thus must use RL for this
        2. ChatGPT SL vs RL
            1. Supervised Learning: Learns from labeled data to make predictions or classifications.
            2. Reinforcement Learning: Learns by interacting with an environment to optimize a long-term reward.

9. MLsyså„æ–¹å‘ç»¼è¿° - Pentium PRO
   https://zhuanlan.zhihu.com/p/104444471
    1. very good, USB CS294 is the key course for MLsys
    1. directions
        1. åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ï¼ˆDistributed DNN Trainingï¼‰
            1. åˆ†å¸ƒå¼MLç³»ç»Ÿè®¾è®¡
            2. Edge Computing
            3. å¤§é‡è®¡ç®—èµ„æºçš„Scheduling / device placement
            4. communicationç›¸å…³
            5. å…¶ä»–sys for MLå¯åšçš„å‘
                1. å­˜å‚¨ / Data Management
        2. æ·±åº¦å­¦ä¹ æ¨¡å‹å‹ç¼©/åŠ é€Ÿ
            1. é€šè¿‡Quantizedï¼ˆé‡åŒ–ï¼‰é™ä½è®¡ç®—ç²¾åº¦è¦æ±‚
            2. æ–°ç¡¬ä»¶ / DL Acclerator
            3. çŸ©é˜µç®—å­ä¼˜åŒ–
            4. AutoML
        3. æ·±åº¦å­¦ä¹ æ¡†æ¶/ç³»ç»Ÿè®¾è®¡
            1. Deep Learning Framework
            2. Inference / Model Serving
            3. æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨
        4. ç”¨MLä¼˜åŒ–ä¼ ç»Ÿçš„systemé—®é¢˜
            1. æ•°æ®åº“å‚æ•°ã€æ“ä½œç³»ç»Ÿé¡µè¡¨ã€æ•°æ®åº“ç´¢å¼•
            2. åŒæ ·çš„scenarioï¼Œä½¿ç”¨æ›´åˆé€‚çš„MLç®—æ³•
            3. å¯»æ‰¾systemç•Œæ›´å¤šå¯ä»¥MLåŒ–çš„åœºæ™¯
    n. related materials
        1. AI-Systems Distributed Training - Joseph E. Gonzalez
           https://ucbrise.github.io/cs294-ai-sys-fa19/assets/lectures/lec06/06_distributed_training.pdf
            1. optimized for iteration and multi-stage computation
            2. Spark, DistBelief, Parameter Server, Ring All-Reduce, Double Binary Tree All-Reduce
            3. With more machines added, batch size is becoming larger, larger batch size isn't always well
                1. Scale the learning rate linearly with the batch size
            4. Dimensions of Parallelism
                1. Data Parallelism
                    1. Synchronous Execution (Most Common)
                    2. Asynchronous Execution (Popular in Research)
                2. Model Parallelism
                    1. Divide the model across machines and replicate the data
                    2. How to best divide a model
                        1. Split individual layers
                        2. Split across layers
                
                3. Pipeline Parallelism
                    1. Combine model and data parallelism to concurrently process multiple layers and batches
                    2. GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism
                    n. related materials
                        1. PipeDream: Generalized Pipeline Parallelism for DNN Training    [2019, SOSP, 510 refs]
                           https://arxiv.org/abs/1806.03377
                            1. Pipeline model parallelism, cut model layers
                            2. PipeDream: æ•°æ®å¹¶è¡Œ+æµæ°´çº¿
                               https://zhuanlan.zhihu.com/p/336849279
                                1. "ç®€å•çš„è¯´å°±æ˜¯ä¸€ä¸ªåŠ¨æ€è§„åˆ’æ¨¡å‹ï¼šæŠŠMå±‚çš„ç½‘ç»œåˆ†ç»™Nä¸ªèŠ‚ç‚¹ç®—"
                                2. "å®é™…ä¸Šç›®å‰æœ€ä¸»æµçš„åˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ æ¡†æ¶ç”¨çš„éƒ½æ˜¯sync SGD" .. "è™½ç„¶æœ‰å¾ˆå¤šäººæå‡ºäº†async SGDçš„è®­ç»ƒï¼Œä½†æ˜¯ç»è¿‡æ— æ•°ç ”ç©¶è€…çš„æ£€éªŒï¼Œå‘ç°å®ƒå¸¦æ¥çš„ç²¾åº¦æŸå¤±æ‰€é€ æˆçš„è´Ÿé¢å½±å“è¿œè¿œå¤§äºåº”ç”¨å®ƒæå‡çš„æ€§èƒ½ã€‚"

                4. Operator Level Parallelism
                    1. Exploiting the parallelism within linear algebra and convolution operations
            n. related materials
                1. How Does Ray, a Distributed AI System, Powers OpenAI's ChatGPT?
                   https://www.analyticsinsight.net/how-does-ray-a-distributed-ai-system-powers-openais-chatgpt/
                    1. ChatGPTèƒŒåçš„å¼€æºAIæ¡†æ¶Rayï¼Œç°åœ¨å€¼10äº¿ç¾å…ƒ
                       https://www.51cto.com/article/743834.html
                2. Deep Learning: A Primer on Distributed Training â€” Part 1 - Shivam Bharuka
                   https://shivambharuka.medium.com/deep-learning-a-primer-on-distributed-training-part-1-d0ae0054bb1c
                    1. Activation Checkpointing
                    2. Networking
                        1. Backward pass can be overlapped with optimizer pass
                        2. Gradient bucketing
                        3. Synchronization Frequency
                        4. Hybrid PS â€” All-reduce
                            1. Herring. Use parameter server based data parallelism for aggregating gradients globally across nodes. Use reduce-scatter and all-reduce operation for gradient averaging locally amongst GPUs in a single node.
                3. Parameter Servers and AllReduce
                   https://xzhu0027.gitbook.io/blog/ml-system/sys-ml-index/parameter-servers 
                    1. Parameter Servers
                        1. Bounded Delay or Stale Synchronous Parallel(SSP)
                    2. Gaia: Geo-Distributed Machine Learning Approaching LAN Speeds
                        1. It is infeasible to move the geo-distributed(or geo-generated) data to a centralized data center before running an ML algorithm over it
                        2. Approximate Synchronous Parallelism (ASP) is based on a key finding that the vast majority of updates to the global ML model parameters from each ML worker machine are insignificant.
                            1. With ASP, these insignificant updates to the same parameter within a data center are aggregated (and thus not communicated to other data centers) until the aggregated updates are significant enough.
                    3. Ring AllReduce
                        1. The main issue with the parameter server's communication strategy(e.g. one parameter server and multiple workers) was that the communication cost grew linearly with the number of GPUs in the system.
                        2. In contrast, a ring allreduce is an algorithm for which the communication cost is constant and independent of the number of GPUs in the system
                        n. related materials
                            1. æµ…è°ˆTensorflowåˆ†å¸ƒå¼æ¶æ„ï¼šring all-reduceç®—æ³•
                               https://zhuanlan.zhihu.com/p/69797852

        2. UCBçš„CS294 19spring/fall
           https://ucbrise.github.io/cs294-ai-sys-sp19/
           https://ucbrise.github.io/cs294-ai-sys-fa19
           https://ucbrise.github.io/cs294-ai-sys-sp22/
           https://berkeley-deep-learning.github.io/cs294-131-s19/
            1. good
            2. CS 294-131: Trustworthy Deep Learning (Special Topics in Deep Learning)
                1. https://berkeley-deep-learning.github.io/cs294-131-s19/
                    1. security/privacy
                    2. adversarial examples
                    3. causality
                    4. fake news defense
                    5. explainability
                    6. uncertainty

        3. CS294: Scheduling Deep Learning Workloads
           https://ucbrise.github.io/cs294-ai-sys-sp19/assets/lectures/lec27/dl-scheduling.pdf
            1. key aspects
                1. Maximize throughput
                2. Fairness
            2. related: Dominant Resource Fairness (DRF) presentation 
        
        4. Model Compression - Joseph E. Gonzalez
           https://ucbrise.github.io/cs294-ai-sys-sp19/assets/lectures/lec22/network_compression.pdf
            1. Approaches to â€œCompressingâ€ Models
                1. Architectural Compression
                    1. Layer Design - Typically using factorization techniques to reduce storage and computation
                        1. MobileNet Paper
                        2. ShuffleNet paper
                    2. Pruning - Eliminating weights, layers, or channels to reduce storage and computation from large pre-trained models
                2. Weight Compression 
                    1. Low Bit Precision Arithmetic - Weights and activations are stored and computed using low bit precision
                    2. Quantized Weight Encoding - Weights are quantized and stored using dictionary encodings
            
            n. related materials
                1. Efficient Processing of Deep Neural Networks: from Algorithms to Hardware Architectures - Vivienne Sze [2019, NIPS]
                   http://eyeriss.mit.edu/2019_neurips_tutorial.pdf?ich_args2=526-06113205060278_e0b61138dc2d908aa0766d50302e6d8a_10001002_9c896324d5cbf0d49239518939a83798_92e0a859ed6aa28355c3deea32562911
                   https://www.youtube.com/watch?v=geLeDFFl8UQ
                    1. 10:00 - 20:00, Very useful charts to understand how DNN works in the networking structure and how to calculate dimensions
                    2. Key metrics and design objectives in DNN, and DNN processor
                        1. Accuracy, latency, throughput.
                        2. Energy of power, hardware cost, range of DNN tasks (flexibility), scalability
                        3. MAC/data, MAC/cycle (PE count) matching issue
                        4. Data movement with DRAM dominates energy consumption
                    3. CPU & GPU Platforms
                        1. Matrix multiplication
                            1. reduce number of multiply, replace with addition
                            2. Fast Fourier Transform
                        2. More MAC per cycle
                            1. SIMT/SIMD
                            2. reduce precision
                        3. Memory access is the bottleneck
                            1. Input data reuse
                        4. High parallelism
                        5. Energy vs Accuracy
                            1. Energy ~ Exp(Accuracy)
                2. The Ultimate Guide to Deep Learning Model Quantization and Quantization-Aware Training - opensource SuperGradients by Deci 
                    https://deci.ai/quantization-and-quantization-aware-training/
                    1. edge devices are resource-constrained
                    2. The model size can typically be reduced by two to four times
                    3. post-training quantization (PTQ) and quantization-aware training (QAT)
                    4. scale quantization: Max, Entropy, Percentile
                    5. Types of Quantization: Naive, Hybrid, and Selective
                    6. selecting the appropriate quantization method, identifying sensitive layers, and fine-tuning your models using quantization-aware training
                    7. Useful Best Practices
                        1. Tips for Post Training Quantization
                            1. Use per-channel granularity for weights and per-tensor for activation
                            2. Quantize residual connections separately by replacing blocks
                            3. Identify sensitive layers and skip them from quantization
                        2. Tips for Quantization-Aware Training
                            1. Start with the best-performing calibrated PTQ model
                            2. Fine-tune for around 10% of the original training schedule
                            3. Use cosine annealing LR schedule starting at 1% of the initial training LR
                            4. Use SGD optimizer with momentum instead of ADAM or RMSProp

        5. ModelDB: An open-source system for Machine Learning model versioning, metadata, and experiment management
           https://github.com/VertaAI/modeldb
            1. Referenced in parent article as "è®­ç»ƒæ•°æ®çš„è§„æ¨¡æ˜¯å¾ˆå¤§çš„ã€‚å¦‚ä½•ä¸ºMLè®¾è®¡ä¸€ä¸ªä¸“ç”¨çš„æ–‡ä»¶ç³»ç»Ÿï¼ˆç±»ä¼¼å¤§æ•°æ®ç•Œçš„HDFSï¼‰æˆ–è€…æ•°æ®åº“æ¥åŠ é€Ÿè¯»æ•°æ®å‘¢ï¼Ÿ ç±»ä¼¼çš„å·¥ä½œæœ‰ç®¡ç†ML modelçš„ModelDB."
            2. key features
                1. Make your ML models reproducible
                    1. model version control
                    2. model metadata
                2. Manage your ML experiments, build performance dashboards, and share reports
                3. Track models across their lifecycle including development, deployment, and live monitoring
            3. Verta Enterprise MLOps Platform
               https://docs.verta.ai/verta/
                1. Experiment Management
                2. Model Catalog
                3. Model Deployment
            4. related materials
                1. Versioning Your ML Models using ModelDB
                   https://songrcs.medium.com/versioning-your-dataset-and-models-using-modeldb-10b0ee3873ed
                2. Model Versioning Done Right: A ModelDB 2.0 Walkthrough - Verta AI
                   https://www.youtube.com/watch?v=U0lyF_lHngo
                    1. why not GIT
                        1. not for large file
                        2. not working with DBMS nor libraries
        
        6. AI-Systems Machine Learning Lifecycle
           https://ucbrise.github.io/cs294-ai-sys-fa19/assets/lectures/lec03/03_ml-lifecycle.pdf
            1. key concepts
                1. Hyperparameters
                2. Model Pipelines, Features, and Feature Engineering
                3. Warm Starting and Fine Tuning
                4. Feedback Loops, Retraining and Continuous Training
            2. model development, training, inference
                1. 80% time spent in data preparation
                2. model composition
                3. inference with Model updates, Feature updates

        7. æ·±åº¦å­¦ä¹ åŠ é€Ÿï¼šç®—æ³•ã€ç¼–è¯‘å™¨ã€ä½“ç³»ç»“æ„ä¸ç¡¬ä»¶è®¾è®¡ - meton
           https://zhuanlan.zhihu.com/p/101544149
            1. very good article. summarizing wide ranges of aspects with inter-connection
            2. highlights
                1.ç®—æ³•é¡¶å±‚
                    1. å¤§è§„æ¨¡åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ï¼ˆå¹¶è¡Œæ¨¡å¼ã€è°ƒåº¦æ¨¡å¼ã€æ›´æ–°ç­–ç•¥ï¼‰
                    2. ä¼˜åŒ–ç®—æ³•
                    3. è½»é‡çº§ç½‘ç»œè®¾è®¡
                    4. ç¥ç»ç½‘ç»œæ¶æ„æœç´¢
                    5. é‡åŒ–ä¸å‰ªæ
                    6. å·ç§¯è¿ç®—çš„ä¼˜åŒ–ã€
                2. æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨
                    1. éœ€æ±‚ä¸ç—›ç‚¹
                    2. TVM
                    3. Pytorch Glow
                    4. Tensorflow XLA
                3. ä½“ç³»ç»“æ„ä¸ç¡¬ä»¶è®¾è®¡
                    1. å…³æ³¨æŒ‡æ ‡
                    2. CPUå’ŒGPUå¹³å°ä¸å…¶è®¾è®¡è€ƒé‡
                    3. Domain-Specific ç¡¬ä»¶è®¾è®¡
                    4. è®¾è®¡å…³æ³¨ç‚¹
                    5. æ·±åº¦å­¦ä¹ åº”ç”¨æ•°æ®é‡ç”¨æœºä¼š
                    6. ä¸¤ç±»è®¾è®¡èŒƒå¼ï¼šTemporal Arch. ä¸ Spatial Arch.
                    7. åŠ é€Ÿå™¨è®¾è®¡å¯ä»¥åˆ©ç”¨çš„ç‰¹æ€§ï¼ˆç¨€ç–ã€ä½ç²¾åº¦ã€å‹ç¼©ï¼‰

            n. related materials
                1. Parameter Servers vs AllReduce
                   https://xzhu0027.gitbook.io/blog/ml-system/sys-ml-index/parameter-servers
                    1. Parameter Serveræ˜¯ä¸­å¿ƒå¼å­˜å‚¨å‚æ•°ï¼ŒAll Reduceæ˜¯æ— ä¸­å¿ƒåˆ†å‘å‚æ•°

                2. PuDianNao: A Polyvalent Machine Learning Accelerator
                   https://www.zhihu.com/question/41216802/answer/124409366
                   https://dl.acm.org/doi/10.1145/2786763.2694358
                    1. æ–‡ç« å…ˆæ˜¯å¯¹ä¸ƒç§æœºå™¨å­¦ä¹ ç®—æ³•çš„è®¡ç®—åŠè®¿å­˜èŒƒå¼è¿›è¡Œäº†åˆ†æ .. è®ºæ–‡ä¸­èŠ±äº†å¤§é‡ç¯‡å¹…ï¼Œä»”ç»†åˆ†æäº†å„ç±»æœºå™¨å­¦ä¹ ç®—æ³•åœ¨è®¿å­˜è¡Œä¸ºã€è®¡ç®—æ¨¡å¼ä¸Šçš„å¼‚åŒ
                        1. Identify time-consuming step, next identify locality property of the time-consuming step
                            1. analyze memory bandwidth. divide-and-conquer
                            2. Tiled code
                        2. interesting
                            1. k-Nearest Neighbors
                            2. k-Means
                            3. Deep Neural Network
                            4. Linear Regression
                            5. Support Vector Machine
                            6. Naive Bayes
                            7.  Classification Tree


        8. æ·±åº¦å­¦ä¹ ç®—æ³•ä¼˜åŒ–ç³»åˆ—ä¸‰ | Google CVPR2018 int8é‡åŒ–ç®—æ³•
           https://zhuanlan.zhihu.com/p/99424468
            1. Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference
                1. å…¥é—¨é‡åŒ–æœ€ç»å…¸çš„è®ºæ–‡ä¹‹ä¸€
            2. è®­ç»ƒåé‡åŒ–(post-training-quantizated)
                1. ä»¥int8çš„å½¢å¼ä¿å­˜ï¼Œä½†åœ¨å®é™…æ¨ç†æ—¶ï¼Œè¿˜éœ€è¦åé‡åŒ–ä¸ºæµ®ç‚¹æ•°ç±»å‹è¿›è¡Œè®¡ç®—
               è®­ç»ƒæ—¶é‡åŒ–(quantization-aware-training)
                1. åœ¨åå‘ä¼ æ’­çš„æ—¶å€™ä»ç„¶å¯¹floatç±»å‹çš„æƒé‡è¿›è¡Œæ¢¯åº¦ä¸‹é™ï¼Œå‰å‘æ¨ç†æ—¶å…¨éƒ¨ä½¿ç”¨int8çš„æ–¹å¼è¿›è¡Œè®¡ç®—
            3. è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§å°†float32é‡åŒ–ä¸ºint8çš„æ–¹æ³•ï¼Œå¹¶ç»™å‡ºäº†ä¸€ä¸ªè®­ç»ƒå’Œæ¨ç†æ¡†æ¶ï¼Œæ¨ç†æ¡†æ¶ä½¿å¾—æ¨¡å‹å¯ä»¥åœ¨èƒ½æ‰§è¡Œæ•´å‹è¿ç®—çš„è®¡ç®—è®¾å¤‡ä¸Šé«˜æ•ˆè¿è¡Œï¼Œè®­ç»ƒæ¡†æ¶å’Œæ¨ç†æ¡†æ¶ç›¸è¾…ç›¸æˆï¼Œå¯ä»¥æ˜¾è‘—é™ä½é‡åŒ–è¿‡ç¨‹ä¸­çš„ç²¾åº¦æŸå¤±ã€‚
                1. r = S(q - Z), qå°±æ˜¯8-bitæ•´æ•°
                2. çº¯æ•´æ•°ç®—æœ¯çŸ©é˜µä¹˜æ³•
                    1. é›¶ç‚¹çš„æœ‰æ•ˆå¤„ç†
                    2. int32ä¸­é—´ç»“æœ
                3. æ¨¡æ‹Ÿé‡åŒ–è®­ç»ƒ
                    1. åœ¨å‰å‘ä¼ æ’­é˜¶æ®µæ¨¡æ‹Ÿé‡åŒ–çš„æ–¹æ³•ï¼Œåå‘ä¼ æ’­å’Œå¹³å¸¸ä¸€æ ·
                    2. å­¦ä¹ é‡åŒ–èŒƒå›´
                    3. Batch normalizationå±‚

        9. ä¸€æ–‡çœ‹æ‡‚æ·±åº¦å­¦ä¹ æ–°ç‹è€…ã€ŒAutoMLã€ï¼šæ˜¯ä»€ä¹ˆã€æ€ä¹ˆç”¨ï¼Ÿ
           https://zhuanlan.zhihu.com/p/42924585
            1. AutoMLå’Œç¥ç»æ¶æ„æœç´¢ï¼ˆNASï¼‰ - æœç´¢æœ€ä¼˜ç¥ç»ç½‘ç»œæ¶æ„ï¼Œä½ åªéœ€è¦æä¾›æ•°æ®
                1. "Neural Architecture Search"

        10. AI-Systems Prediction Serving - Joseph E. Gonzalez
            https://ucbrise.github.io/cs294-ai-sys-fa19/assets/lectures/lec07/07_prediction-serving.pdf
            1. Serving Pre-materialized Predictions
            2. Hybrid Offline + Online Learning
            3. VELOX Architecture
            4. Clipper
                1. Selection Policy: Estimate confidence
            5. KUNA
            6. Pretzel: Opening the Black Box of Machine Learning Prediction Serving Systems

        11. æ‰‹æŠŠæ‰‹å¸¦ä½ é¨æ¸¸TVM
            https://zhuanlan.zhihu.com/p/50529704
            1. "è€Œå¯¹äºInferenceæ¥è¯´ï¼Œä»¥æˆ‘ä¹‹æ‰€è§ï¼Œå…¶å®æ˜¯â€œç¾¤é›„é€é¹¿â€"
               "ä¼šè·‘åˆ°çš„è®¾å¤‡å¯èƒ½ä¼šæ˜¯å¤šç§å¤šæ ·çš„ï¼Œå¦‚Intel CPU / Intel GPU / ARM CPU / ARM GPU / NV GPU / FPGA / AIèŠ¯ç‰‡ç­‰"
               "æˆ‘ä»¬èƒ½ä¸èƒ½åšä¸€ä¸ªåŸºäºç¼–è¯‘ä¼˜åŒ–æ€æƒ³çš„æ¨ç†æ¡†æ¶å‘¢ï¼Ÿç­”æ¡ˆå°±æ˜¯ï¼šTVM"

        12. Learning Key-Value Store Design    [2019, 9 refs]
            https://arxiv.org/pdf/1907.05443.pdf
            1. Referenced in the parent article "å®ƒæå‡ºäº†Design Continuumçš„æ¦‚å¿µï¼šå­˜å‚¨ç³»ç»Ÿä¸­çš„å¾ˆå¤šæ•°æ®ç»“æ„æœ¬è´¨ä¸Šæ˜¯å¾ˆåƒçš„ï¼ˆarise from the very same set of fundamental design principlesï¼‰ï¼Œä¾‹å¦‚B+tree, LSM-tree, LSH-tableç­‰ï¼Œä½†å®ƒä»¬å´æœ‰ä¸åŒçš„åº”ç”¨åœºæ™¯ï¼ˆæ¯”å¦‚KV Storeä¸­ç”¨LSMå°±æ¯”B+ Treeæ›´åˆé€‚ï¼‰ï¼Œå¾ˆéš¾æœ‰ä¸€ä¸ªåå…¨åç¾çš„è®¾è®¡ã€‚è¿™è¯´æ˜å®ƒä»¬æœ‰ç›¸äº’æ›¿æ¢çš„ç©ºé—´ã€‚è¿™æ ·æˆ‘ä»¬å¯ä»¥å°†ä¸åŒæ•°æ®ç»“æ„çš„é€‰æ‹©ä¹Ÿä½œä¸ºå­˜å‚¨ç³»ç»Ÿçš„ä¸€ä¸ªknobï¼Œæ ¹æ®å…·ä½“workloadå’Œç¡¬ä»¶çš„æƒ…å†µæ¥è‡ªåŠ¨é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„åº•å±‚æ•°æ®ç»“æ„ï¼ˆfind a close to optimal data structure design for a key-value store given a target workload and hardware environmentï¼‰ã€‚"

    2. Federated Learning at Scale - xzhu0027
       https://xzhu0027.gitbook.io/blog/ml-system/sys-ml-index/towards-federated-learning-at-scale-system-design
       https://xzhu0027.gitbook.io/blog/ml-system/sys-ml-index/federated-learning-at-scale-part-i
        1. Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized.   FL allows for smarter models, lower latency, less bandwidth usage, and less power consumption, all while ensuring privacy and user experiences.
        2. applications
            1. Healthcare
            2. enterprise collaboration
            3. privacy matters
        3. security and privacy
            1. homomorphic encryption and secure aggregation
                1. encrypting the model updates such that the server can still perform the algebraic operations necessary to combine them, but updates not sent in plaintext
            2. differential privacy.
                1. The basic idea is to add random noise to the individual updates. These updates are going to be accumulated, and thus your noise should cancel with all the noise other people have added
        4. Advances and Open Problems in Federated Learning by Kairouz et al.

    3. å¤§æ¨¡å‹æ¨ç†æ¡†æ¶æ¦‚è¿° - åƒæœå†»ä¸åæœå†»çš®
       https://zhuanlan.zhihu.com/p/659792625?utm_id=0
        1. vLLM
        2. HuggingFace TGI
        3. FasterTransformer
        4. FlexFlow Server
        5. LMDeploy

    4. å¤§è¯­è¨€æ¨¡å‹æ¨ç†æ€§èƒ½ä¼˜åŒ–ç»¼è¿° - Young
       https://zhuanlan.zhihu.com/p/656485997?utm_id=0
        1. very good article. The top chart summarize all directions
        2. highlights
            1. LLMæ¨ç†ä¼˜åŒ–
                1. æ˜¾å­˜ç›¸å…³ä¼˜åŒ–
                    1. KV Cache
                    2. Paged Attention
                2. è®¡ç®—ç›¸å…³ä¼˜åŒ–
                    1. ç®—å­èåˆ
                    2. é«˜æ€§èƒ½ç®—å­
                3. æœåŠ¡ç›¸å…³ä¼˜åŒ–
                    1. Continuous Batching
                    2. Dynamic Batching
                    3. å¼‚æ­¥ Tokenize / Detokenize
                4. åˆ†å¸ƒå¼ç›¸å…³ä¼˜åŒ–
                    1. æ¨¡å‹å¹¶è¡Œ
                        1. Column Parallel,  Row Parallel
                        2. Megatron-LM
                5. ä½æ¯”ç‰¹é‡åŒ–
                    1. æƒé‡é‡åŒ–
                    2. æƒé‡å’Œæ¿€æ´»åŒæ—¶é‡åŒ–
                    3. KV Cacheé‡åŒ–
                    4. åŸºäºç¡¬ä»¶ç‰¹ç‚¹çš„é‡åŒ–ï¼šè‹±ä¼Ÿè¾¾ Hopper æ¶æ„ä¸‹çš„ FP8
                6. å…¶ä»–æ–°æŠ€æœ¯
                    1. æŠ•æœºé‡‡æ ·ï¼ˆSpeculative decodingï¼‰
                    2. ç¾æœèå¤´ï¼ˆMedusa headï¼‰

19. å¤§æ¨¡å‹é¢è¯•å…«è‚¡ - èŠ±ç”˜è€…æµ…ç‹
    https://zhuanlan.zhihu.com/p/643560888
    1. very good.
    n. related materials
        1. Understanding and Coding the Self-Attention Mechanism of Large Language Models From Scratch
           https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html
            1. useful
        2. Build Better Deep Learning Models with Batch and Layer Normalization
           https://www.pinecone.io/learn/batch-layer-normalization/
            n. related materials
                1. Different Normalization Layers in Deep Learning
                   https://towardsdatascience.com/different-normalization-layers-in-deep-learning-1a7214ff71d6
        3. Understanding Backpropagation Algorithm
           https://towardsdatascience.com/understanding-backpropagation-algorithm-7bb3aa2f95fd
            1. The Challenge of Vanishing/Exploding Gradients in Deep Neural Networks
               https://www.analyticsvidhya.com/blog/2021/06/the-challenge-of-vanishing-exploding-gradients-in-deep-neural-networks/
            2. The Vanishing/Exploding Gradient Problem in Deep Neural Networks
               https://towardsdatascience.com/the-vanishing-exploding-gradient-problem-in-deep-neural-networks-191358470c11
            3. Lecture 15: Exploding and Vanishing Gradients - Roger Grosse
               https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L15%20Exploding%20and%20Vanishing%20Gradients.pdf
        4. æ¢¯åº¦çˆ†ç‚¸ (exploding gradients) vs æ¢¯åº¦æ¶ˆå¤± (gradient vanishing)
            1. Transformers Explained Visually (Part 3): Multi-head Attention, deep dive - Ketan Doshi
               https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853
            2. ä¸‡å­—é•¿æ–‡è§£è¯»Transformeræ¨¡å‹å’ŒAttentionæœºåˆ¶ - æ½˜å°å°
               https://zhuanlan.zhihu.com/p/104393915
            3. Transformerå‡çº§ä¹‹è·¯ï¼š1ã€Sinusoidalä½ç½®ç¼–ç è¿½æ ¹æº¯æº - è‹å‰‘æ—
               https://kexue.fm/archives/8231
        5. ç»¼è¿°blogï¼šProcessing Data for LLM
           https://wandb.ai/wandb_gen/llm-data-processing/reports/Processing-Data-for-Large-Language-Models--VmlldzozMDg4MTM2
            1. Handling junk data
            2. De-duplication
            3. Decontamination
            4. Toxicity and Bias Control
            5. Personal Identifiable Information Control
            6. Prompt Control
        6. çº¢é›¨ç“¢æ³¼ï¼šä¸€æ–‡çœ‹æ‡‚ï¼šå¦‚ä½•å……åˆ†é«˜æ•ˆè®­ç»ƒå¤šè½®å¯¹è¯å¤§æ¨¡å‹
           https://zhuanlan.zhihu.com/p/645517143
        7. Memory cost: Transformer Inference Arithmetic - kipply's blog
           https://kipp.ly/transformer-inference-arithmetic/
        8. å½“çº¢ç‚¸å­é¸¡ LoRAï¼Œæ˜¯å½“ä»£å¾®è°ƒ LLMs çš„æ­£ç¡®å§¿åŠ¿ï¼Ÿ
           https://zhuanlan.zhihu.com/p/618894919
        9. Current Best Practices for Training LLMs from Scratch - Rebecca Li, Andrea Parker, Justin Tenuto
           https://uploads-ssl.webflow.com/5ac6b7f2924c656f2b13a88c/6435aabdc0a041194b243eef_Current%20Best%20Practices%20for%20Training%20LLMs%20from%20Scratch%20-%20Final.pdf
            1. Very useful for introduction. Good.
            2. main domains of LLMs
                1. use commercial API vs opensource vs pre-train by yourself
                2. choose model size, training data size
                3. hardware capabilities
                    1. memory efficiency
                    2. compute efficiency
                4. Parallelization
                    1. batch size
                    2. data parallelism - training data sharding 
                        1. problems
                            1. backward pass to pass all gradients to all GPUs
                            2. replicates model and optimizer to each GPU
                    3. Tensor parallelism - divide large matrix multiplications
                        1. problems
                            1. communication cost
                    4. pipeline parallelism and model parallelism - inter-layer parallelism
                        1. problems
                            1. cannot scale flexibly due to bound to model structure
                    5. examples
                        1. Megatron-LM PTD-P technology
                        2. Estimating ğŸŒ´PaLM's training cost
                           https://blog.heim.xyz/palm-training-cost/
                            1. good as to show COGS cost estimation method
                            2. public cloud prices act as the baseline building blocks
                5. data collection
                    1. dataset diversity for LLM
                    2. dataset pre-processing
                6. Tokenization methods
                    1. Word-based tokenization
                    2. Character-based tokenization
                    3. Subword-based tokenization
                7. Pre-training steps
                    1. Experiments and Hyperparameter Search
                        1. Experiments can involve any or all of the following: weight initialization, positional embeddings, optimizer, activation, learning rate, weight decay, loss function, sequence length, number of layers, number of attention heads, number of parameters, dense vs. sparse layers, batch size, and dropout.
                    2. Training instability
                        1. avoiding loss spikes
                8. Model evaluation
                    1. popular standard evaluation benchmarks
                    2. the listing is useful
                9. Bias andToxicity
                    1. bias and toxicity benchmarks
                10. Instruction Tuning
                    1. Instruction tuning tunes full model parameters as opposed to freezing a part of them in Parameter-efficient Fine Tuning
                    2. Instruction tuning is universally effective on tasks naturally verbalized as instructions (e.g., NLI, QA, translation), but it is a little trickier for tasks like reasoning.
                    To improve for these tasks, you'll want to include Chain-of-Thought examples during tuning
                    2. Reinforcement Learning Through Human Feedback (RLHF)
                        1. an extension of Instruction Tuning
                        n. related materials
                            1. å¼ºåŒ–å­¦ä¹ ä»é›¶åˆ°RLHFï¼ˆå…«ï¼‰ä¸€å›¾æ‹†è§£RLHFä¸­çš„PPO
                               https://zhuanlan.zhihu.com/p/635757674
                            2. ChatGPT explained: A Guide to Conversational AI w/ InstructGPT, PPO, Markov, RLHF
                               https://www.youtube.com/watch?v=GMkszGzFOgw
                                1. Policy Gradients in a Nutshell - Sanyam Kapoor
                                   https://towardsdatascience.com/policy-gradients-in-a-nutshell-8b72f9743c5d
                                    1. useful to understand RL training basics
                                2. Proximal Policy Optimization (PPO) Explained
                                   https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b
                                    1. interesting. useful.
                                3. Understanding the Finite Element Method
                                   https://www.youtube.com/watch?v=GHjopp47vvQ
                                    1. interesting. useful.
                            3. å¦‚ä½•ç›´è§‚ç†è§£PPOç®—æ³•?[ç†è®ºç¯‡] - å¼ æ–¯ä¿Š
                               https://zhuanlan.zhihu.com/p/111049450

    n+1. related materials
        1. PTD-P: Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM    [2021, 257 refs, NVIDIA]
           https://arxiv.org/abs/2104.04473
            1. very good. state of art work to tell how parallelism should be organized in LLM.
               the recommended approach is running tensor + pipeline model parallelism.
               leverage intra server NVLink to fit the high communication cost of tensor parallelism
               the paper also provides detailed performance formulas and analysis, which can be used as a reference
            2. highlights
                0. Key paper problem
                    1. How should parallelism techniques be combined to maximize the training throughput of large models given a batch size while retaining strict optimizer semantics?
                    2. ensure strict optimizer semantics, need sync pipeline flush, thus introduces the pipeline bubble time
                        1. Not in this paper, but Pipeline parallelism can also be implemented with relaxed semantics
                            1. Asynchronous and bounded-staleness
                1. Selene supercomputer cluster setup
                    1. ~1T parameters.
                    2. NVIDIA DGX A100 servers
                        1. 8 * 80GB-A100 CPUs, with NVLink and NVSwitch
                        2. 8 * NVIDIA Mellanox 200GB HDR Infiniband HCAs
                    3. 3072 GPUs in cluster
                        1. bisection bandwidth
                           point-to-point 892 GB/s,
                           or all-reduce 12.9TB/s 
                    4. checkpoint of size 13.8 TB
                2. formula calculation - this is the good part
                    1. pipeline bubble time fraction
                    2. memory consumption
                    3. flops and throughput
                    4. microbatch size
                    5. model parameter size
                    6. end2end training time
                3. model parallelism
                    1. pipeline model parallelism - this is the good part
                        1. innovative PipeDream-Flush (same authors) schedule. Though pipeline bubble time is the same, but it reduces needed GPU memory by limiting the number of in-flight microbatches
                        2. more optimization, interleaved stages
                        3. Limitations
                            1. designed for LLM, that each device can assign an equal number of transformer blocks
                            2. the number of model layers limits the scalability
                    2. Tensor and pipeline model parallelism
                        1. This is the recommended approach by this paper
                        2. tensor model parallelism be used to degree g, given g GPUs per server.
                           pipeline model parallelism be used to distribute across servers.
                        3. GEMM matrix multiplication in parallel
                    3. data model parallelism
                        1. data and pipeline model parallelism doesn't show better performance vs tensor and pipeline model
                            1. Note, tensor parallelism needs all-reduce communication which is expensive, but it can be done within the server leveraging high speed NVLink
                        2. data and tensor model parallelism is even worse
                        3. my questions
                            1. how about data + tensor + pipeline parallelism?
                4. other optimizations
                    1. activation recomputation
                    2. communication scatter/gather
                    3. all-reduce, ring-reduce

        2. Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, the Worldâ€™s Largest and Most Powerful Generative Language Model    [2022, 325 refs, Microsoft]
           https://github.com/microsoft/Megatron-DeepSpeed
           https://arxiv.org/abs/2201.11990
           https://www.microsoft.com/en-us/research/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/
            1. Tensor parallel intra server with Megatron, pipeline parallelism across server with Deepspeed. Training and evaluation.
            2. highlights
                1. background
                    1. In isolation, existing parallelism strategies such as data, pipeline, or tensor-slicing have trade-offs in memory and compute efficiency and cannot be used to train models at this scale.
                        1. Data parallelism achieves good compute efficiency, but it replicates model states and cannot leverage aggregate distributed memory.
                        2. Tensor-slicing requires significant communication between GPUs that limits compute efficiency beyond a single node where high-bandwidth NVLink is not available.
                        3. Pipeline parallelism can scale efficiently across nodes. However, to be compute-efficient, it requires large batch sizes, coarse grain parallelism, and perfect load balancing, which is not possible at scale.
                2. solution
                    1. The system uses tensor-slicing from Megatron-LM to scale the model within a node and uses pipeline parallelism from DeepSpeed to scale the model across nodes
                    2. mixed precision on the NVIDIA DGX SuperPOD-based Selene(opens in new tab) supercomputer powered by 560 DGX A100 servers networked with HDR InfiniBand in a full fat tree configuration
                    3. We largely built our training dataset based on prior work, The Pile
                        1. The Pile: An 800GB Dataset of Diverse Text for Language Modeling
                           https://arxiv.org/abs/2101.00027
                3. different parallelism models - this is a good introduction
                    1. problems of data parallelism
                        1. data parallelism relies on scaling the batch size with the number of data-parallel workers, and cannot be made arbitrarily large without affecting model quality
                        2. Data parallelism replicates the model and optimizer across all workers, and therefore is not memory efficient
                        3. the communication cost of aggregating gradients increases with the model size and can limit compute efficiency on large models
                    2. Tensor Model Parallelism
                        1. Tensor parallelism reduces the memory footprint of the model proportional to the number of workers
                        2. tensor parallelism requires high communication bandwidth to be efficient and is best kept within a single DGX sever where high bandwidth NVLink is available
                    3. Pipeline Model Parallelism
                        1. Pipeline parallelism reduces memory proportionally to the number of pipeline stages, allowing model size to scale linearly with the number of workers.
                            1. However, pipeline parallelism does not reduce the memory footprint for the activations of each layer. 
                            2. Additionally, each worker must store the activations for all micro-batches in flight.
                        2. Pipeline parallelism has the smallest communication overhead of the three approaches, as it only communicates the activations between the pipeline stage boundaries
                        3. The degree of pipeline parallelism is bounded by the depth of the model, and increasing the pipeline dimension decreases the compute efficiency
                            1. pipeline bubble
                4. training dataset
                    1. many details here
                5. model evaluation
                    1. many details here
                6. others
                    1. gradient accumulation optimization

            n. related works
                1. ZeRO: DeepSpeed: Extreme-scale model training for everyone    [2020, Microsoft]
                   https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/
                   https://www.microsoft.com/en-us/research/project/deepspeed/publications/
                   https://github.com/xitu/gold-miner/blob/master/article/2020/deepspeed-extreme-scale-model-training-for-everyone.md
                    1. Topology aware 3D mapping (Figure 2)
                        1. ZeRO data parallel
                            1. ZeRO & DeepSpeed: New system optimizations enable training models with over 100 billion parameters
                               https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/
                                1. the animation sounds interesting. it's an algorithm with good potential, sharded with parallel, extra communication cost, but not adding extra memory to hold temporary data
                            2. This is just the usual DataParallel (DP), except, instead of replicating the full model params, gradients and optimizer states, each GPU stores only a slice of it. And then at run-time when the full layer params are needed just for the given layer, all GPUs synchronize to give each other parts that they miss - this is it.
                        2. Pipeline parallel
                        3. Model parallel
                            1. it seems the pipeline parallel and model parallel are just referring to the pipeline model parallel in Megatron-LM paper
                        n. related materials
                            1. Model Parallelism - huggingface.io
                               https://huggingface.co/docs/transformers/v4.15.0/parallelism
                                1. DataParallel (DP)
                                2. TensorParallel (TP)
                                3. PipelineParallel (PP)
                                4. Zero Redundancy Optimizer (ZeRO)
                                5. Sharded DDP

1. å¿…çœ‹ï¼šå¾®è½¯166é¡µè®ºæ–‡è§£è¯» GPT-4V ä¸­æ–‡ç‰ˆï¼ˆç²¾æ ¡ï¼‰ã€Šå¤šæ¨¡æ€çš„æ–°æ—¶ä»£ã€‹ -  æç§‰å®‡ AIhackathon
   https://mp.weixin.qq.com/s/a8Y_yU5XYgJhQ2xMuTK13w
    1. æ¥è‡ªè¿™äº›æ ·æœ¬çš„è§‚å¯Ÿè¡¨æ˜ï¼ŒGPT-4V åœ¨å¤„ç†ä»»æ„äº¤é”™çš„å¤šæ¨¡æ€è¾“å…¥ï¼ˆinterleaved multimodal inputsï¼‰å’Œå…¶èƒ½åŠ›çš„é€šç”¨æ€§æ–¹é¢å…·æœ‰å‰æ‰€æœªæœ‰çš„èƒ½åŠ›ï¼Œä½¿ GPT-4V æˆä¸ºä¸€ä¸ªå¼ºå¤§çš„å¤šæ¨¡æ€é€šç”¨ç³»ç»Ÿã€‚
        1. The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)
           https://arxiv.org/abs/2309.17421
            1. interesting
    2. Highlights
        1. æ‹¬å¼€æ”¾ä¸–ç•Œè§†è§‰ç†è§£ï¼ˆopen-world visual understandingï¼‰ã€è§†è§‰æè¿°ï¼ˆvisual descriptionï¼‰ã€å¤šæ¨¡æ€çŸ¥è¯†ï¼ˆmultimodal knowledgeï¼‰ã€å¸¸è¯†ï¼ˆcommonsenseï¼‰ã€åœºæ™¯æ–‡æœ¬ç†è§£ï¼ˆscene text understandinï¼‰ã€æ–‡æ¡£æ¨ç†ï¼ˆdocument reasoningï¼‰ã€ç¼–ç ï¼ˆcodingï¼‰ã€æ—¶é—´æ¨ç†ï¼ˆtemporal reasoninï¼‰ã€æŠ½è±¡æ¨ç†ï¼ˆabstract reasoningï¼‰ã€æƒ…æ„Ÿç†è§£ï¼ˆemotion understandingï¼‰ ï¼Œ è¿˜æœ‰å¾ˆå¤š
        2. GPT-4V çš„ä¸åŒå·¥ä½œæ¨¡å¼ï¼Œä¾‹å¦‚æŒ‡ä»¤è°ƒæ•´ï¼ˆinstruction tuningï¼‰ã€ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆin-context learningï¼‰å’Œå…¶ä»–ç´§æ€¥ç”¨é€”ï¼ˆand other emergent usagesï¼‰ã€‚

2. å›½äº§AIèŠ¯ç‰‡çš„å¤§æ¨¡å‹ç³»ç»Ÿçš„ç ”ç©¶ - å¹²ä¸€è¡ŒAIä¸€è¡Œ ITç”Ÿæ´»è·¯æ¼«æ¼« 
   https://mp.weixin.qq.com/s/bc9tFaftT75RpWQ9SUjb6Q
    1. å›½äº§GPUçš„ç”Ÿæ€ç³»ç»Ÿçš„10å¤§æ–¹é¢
        1. ç¼–ç¨‹æ¡†æ¶ï¼šåˆ©ç”¨åŸºæœ¬ç®—å­å¿«é€Ÿæ„å»ºäººå·¥æ™ºèƒ½æ¨¡å‹ï¼Œä»¥é™ä½ç¼–å†™äººå·¥æ™ºèƒ½æ¨¡å‹çš„å¤æ‚åº¦ã€‚ä¾‹å¦‚:PyTorchï¼ŒTensorFlow
        2. å¹¶è¡ŒåŠ é€Ÿï¼šä¸ºå¤šæœºå¤šå¡ç¯å¢ƒæä¾›äººå·¥æ™ºèƒ½æ¨¡å‹å¹¶è¡Œè®­ç»ƒçš„èƒ½åŠ›ï¼Œç¡®ä¿èƒ½å¤Ÿæ”¯æŒæ•°æ®å¹¶è¡Œã€æ¨¡å‹å¹¶è¡Œã€æµæ°´çº¿å¹¶è¡Œã€å¼ é‡å¹¶è¡Œç­‰ã€‚ä¾‹å¦‚ï¼šå¾®è½¯DeepSpeedï¼Œè‹±ä¼Ÿè¾¾Megatron-LM
        3. é€šä¿¡åº“ï¼šæä¾›è·¨æœºè·¨å¡çš„é€šä¿¡èƒ½åŠ›ï¼Œæ”¯æŒäººå·¥æ™ºèƒ½æ¨¡å‹è®­ç»ƒæ‰€éœ€çš„å„ç§é€šä¿¡æ¨¡å¼ï¼Œèƒ½æ ¹æ®åº•å±‚ç½‘ç»œç‰¹ç‚¹å……åˆ†åˆ©ç”¨ç½‘ç»œé€šä¿¡å¸¦å®½ã€‚ä¾‹å¦‚ï¼šè‹±ä¼Ÿè¾¾NCCLåº“ï¼Œè¶…ç®—çš„MPIé€šä¿¡åº“
        4. ç®—å­åº“ï¼šç®—å­åº“æä¾›äººå·¥æ™ºèƒ½æ¨¡å‹æ‰€éœ€åŸºæœ¬æ“ä½œçš„é«˜æ€§èƒ½å®ç°ï¼Œè¦æ±‚å°½å¯èƒ½è¦†ç›–å…¸å‹äººå·¥æ™ºèƒ½æ¨¡å‹æ‰€éœ€çš„æ“ä½œï¼Œè¦æ±‚ç®—å­åº“èƒ½å……åˆ†å‘æŒ¥åº•å±‚ç¡¬ä»¶çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼šè‹±ä¼Ÿè¾¾cuDNN,cuBLAS
        5. Alç¼–è¯‘å™¨ï¼šäººå·¥æ™ºèƒ½ç¨‹åºçš„ç›®æ ‡ä»£ç ä¾é AIç¼–è¯‘å™¨ç”Ÿæˆã€‚å¯¹äºç®—å­åº“ä¸èƒ½æä¾›çš„æ“ä½œï¼Œé€šè¿‡Alç¼–è¯‘å™¨å¯ä»¥è‡ªåŠ¨ç”Ÿæˆé«˜æ•ˆç›®æ ‡ä»£ç ã€‚ä¾‹å¦‚ï¼šXLAï¼ŒTVM
        6. ç¼–ç¨‹è¯­è¨€ï¼šèƒ½å¤Ÿç¼–å†™äººå·¥æ™ºèƒ½æ¨¡å‹çš„åŸºæœ¬ç®—å­ï¼Œè¦†ç›–åº•å±‚ç¡¬ä»¶åŠŸèƒ½ä»¥å……åˆ†å‘æŒ¥ç¡¬ä»¶æ€§èƒ½ï¼Œæ”¯æŒåœ¨å¼‚æ„å¤„ç†å™¨ä¸Šç¼–å†™å¹¶è¡Œç¨‹åºã€‚ä¾‹å¦‚è‹±ä¼Ÿè¾¾çš„CUDAï¼ŒIntelçš„OneAPI
        7. è°ƒåº¦å™¨ï¼šæä¾›åœ¨å¤§è§„æ¨¡ç³»ç»Ÿä¸Šé«˜æ•ˆè°ƒåº¦äººå·¥æ™ºèƒ½ä»»åŠ¡çš„èƒ½åŠ›ã€‚é€šè¿‡è®¾è®¡é«˜æ•ˆè°ƒåº¦ç®—æ³•ï¼Œæé«˜é›†ç¾¤èµ„æºåˆ©ç”¨ç‡ã€‚ä¾‹å¦‚ï¼šk8sï¼Œåä¸ºçš„ModeArts
        8. å†…å­˜åˆ†é…ç³»ç»Ÿï¼šé’ˆå¯¹äººå·¥æ™ºèƒ½åº”ç”¨ç‰¹ç‚¹æä¾›é«˜æ•ˆçš„å†…å­˜åˆ†é…ç­–ç•¥ã€‚
        9. å®¹é”™ç³»ç»Ÿï¼šæä¾›åœ¨ç¡¬ä»¶å‘ç”Ÿæ•…éšœåå¿«é€Ÿæ¢å¤æ¨¡å‹è®­ç»ƒçš„èƒ½åŠ›ã€‚
        10. å­˜å‚¨ç³»ç»Ÿï¼šæ”¯æŒè®­ç»ƒè¿‡ç¨‹ä¸­é«˜æ•ˆçš„æ•°æ®è¯»å†™(æ£€æŸ¥ç‚¹ã€è®­ç»ƒæ•°æ®ç­‰)ã€‚

3. Book THE ART OF ASKING CHATGPT FOR HIGH-QUALITY ANSWERS - IBRAHIM JOHN
   https://www.amazon.com/Art-Asking-ChatGPT-High-Quality-Answers/dp/B0BT2JB67Y
    1. Task, instruction, role
    2. Self-consistency prompt - "ensure the summary is consistent with "
    3. Knowledge integration prompt - "Update the existing knowledge about XX with the following information YY"
    4. Specifying the template or style
    5. Adversary prompt - "Generate text that is difficult to classify as XX." "difficult to classify as having the statement of YY."
    6. Clustering prompt - "Group the following customer reviews into clusters based on sentiment"
    8. Let ChatGPT learn examples first. Give ChatGPT examples in prompt
    9. Text classification prompt - "Classify them into different categories such as XX, YY, ZZ"
    10. How to avoid & bypass AI content detectors
        1. using high Perplexity and Burstiness method
        2. let ChatGPT incorporate your own content
        3. remove commonly used connecting words used by ChatGPT
        4. give ChatGPT your own writing style and tone
    11. Generate by seed word.
```